{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "id": "gCVDEsGB1b60"
   },
   "source": [
    "______________________________________________________\n",
    "# Soldier Race Classification Project\n",
    "______________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Y5-Kay1Eqvdj"
   },
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "K7UZHtvu1b62"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "id": "OqnRjwHB1b64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pyforest\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "\n",
    "#Enabling the offline mode for interactive plotting locally\n",
    "from plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "\n",
    "#To display the plots\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc(clf, X_test, y_test, n_classes, figsize=(5,5)):\n",
    "    y_score = clf.decision_function(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc_for_tree(clf, X_test, y_test, n_classes, figsize=(5,5)):\n",
    "    y_score = clf.predict_proba(X_test)\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # calculate dummies once\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver operating characteristic example')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for label %i' % (roc_auc[i], i))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "C5lJeTBu1b65"
   },
   "source": [
    "## Ingest Data from links below and make a dataframe\n",
    "- Soldiers Male : https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr\n",
    "- Soldiers Female : https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "hidden": true,
    "id": "tG5BsWraqX_y",
    "outputId": "a6e730fa-6848-4cfc-becb-284fc8cc99e5"
   },
   "outputs": [],
   "source": [
    "df_male = pd.read_csv('https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr',\n",
    "                      encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = pd.read_csv('https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq',\n",
    "                      encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectid</th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>bideltoidbreadth</th>\n",
       "      <th>bimalleolarbreadth</th>\n",
       "      <th>bitragionchinarc</th>\n",
       "      <th>bitragionsubmandibulararc</th>\n",
       "      <th>bizygomaticbreadth</th>\n",
       "      <th>buttockcircumference</th>\n",
       "      <th>buttockdepth</th>\n",
       "      <th>buttockheight</th>\n",
       "      <th>buttockkneelength</th>\n",
       "      <th>buttockpopliteallength</th>\n",
       "      <th>calfcircumference</th>\n",
       "      <th>cervicaleheight</th>\n",
       "      <th>chestbreadth</th>\n",
       "      <th>chestcircumference</th>\n",
       "      <th>chestdepth</th>\n",
       "      <th>chestheight</th>\n",
       "      <th>crotchheight</th>\n",
       "      <th>crotchlengthomphalion</th>\n",
       "      <th>crotchlengthposterioromphalion</th>\n",
       "      <th>earbreadth</th>\n",
       "      <th>earlength</th>\n",
       "      <th>earprotrusion</th>\n",
       "      <th>elbowrestheight</th>\n",
       "      <th>eyeheightsitting</th>\n",
       "      <th>footbreadthhorizontal</th>\n",
       "      <th>footlength</th>\n",
       "      <th>forearmcenterofgriplength</th>\n",
       "      <th>forearmcircumferenceflexed</th>\n",
       "      <th>forearmforearmbreadth</th>\n",
       "      <th>forearmhandlength</th>\n",
       "      <th>functionalleglength</th>\n",
       "      <th>handbreadth</th>\n",
       "      <th>handcircumference</th>\n",
       "      <th>handlength</th>\n",
       "      <th>headbreadth</th>\n",
       "      <th>headcircumference</th>\n",
       "      <th>headlength</th>\n",
       "      <th>heelanklecircumference</th>\n",
       "      <th>heelbreadth</th>\n",
       "      <th>hipbreadth</th>\n",
       "      <th>hipbreadthsitting</th>\n",
       "      <th>iliocristaleheight</th>\n",
       "      <th>interpupillarybreadth</th>\n",
       "      <th>interscyei</th>\n",
       "      <th>interscyeii</th>\n",
       "      <th>kneeheightmidpatella</th>\n",
       "      <th>kneeheightsitting</th>\n",
       "      <th>lateralfemoralepicondyleheight</th>\n",
       "      <th>lateralmalleolusheight</th>\n",
       "      <th>lowerthighcircumference</th>\n",
       "      <th>mentonsellionlength</th>\n",
       "      <th>neckcircumference</th>\n",
       "      <th>neckcircumferencebase</th>\n",
       "      <th>overheadfingertipreachsitting</th>\n",
       "      <th>palmlength</th>\n",
       "      <th>poplitealheight</th>\n",
       "      <th>radialestylionlength</th>\n",
       "      <th>shouldercircumference</th>\n",
       "      <th>shoulderelbowlength</th>\n",
       "      <th>shoulderlength</th>\n",
       "      <th>sittingheight</th>\n",
       "      <th>sleevelengthspinewrist</th>\n",
       "      <th>sleeveoutseam</th>\n",
       "      <th>span</th>\n",
       "      <th>stature</th>\n",
       "      <th>suprasternaleheight</th>\n",
       "      <th>tenthribheight</th>\n",
       "      <th>thighcircumference</th>\n",
       "      <th>thighclearance</th>\n",
       "      <th>thumbtipreach</th>\n",
       "      <th>tibialheight</th>\n",
       "      <th>tragiontopofhead</th>\n",
       "      <th>trochanterionheight</th>\n",
       "      <th>verticaltrunkcircumferenceusa</th>\n",
       "      <th>waistbacklength</th>\n",
       "      <th>waistbreadth</th>\n",
       "      <th>waistcircumference</th>\n",
       "      <th>waistdepth</th>\n",
       "      <th>waistfrontlengthsitting</th>\n",
       "      <th>waistheightomphalion</th>\n",
       "      <th>weightkg</th>\n",
       "      <th>wristcircumference</th>\n",
       "      <th>wristheight</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Component</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027</td>\n",
       "      <td>266</td>\n",
       "      <td>1467</td>\n",
       "      <td>337</td>\n",
       "      <td>222</td>\n",
       "      <td>1347</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>274</td>\n",
       "      <td>493</td>\n",
       "      <td>71</td>\n",
       "      <td>319</td>\n",
       "      <td>291</td>\n",
       "      <td>142</td>\n",
       "      <td>979</td>\n",
       "      <td>240</td>\n",
       "      <td>882</td>\n",
       "      <td>619</td>\n",
       "      <td>509</td>\n",
       "      <td>373</td>\n",
       "      <td>1535</td>\n",
       "      <td>291</td>\n",
       "      <td>1074</td>\n",
       "      <td>259</td>\n",
       "      <td>1292</td>\n",
       "      <td>877</td>\n",
       "      <td>607</td>\n",
       "      <td>351</td>\n",
       "      <td>36</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>247</td>\n",
       "      <td>802</td>\n",
       "      <td>101</td>\n",
       "      <td>273</td>\n",
       "      <td>349</td>\n",
       "      <td>299</td>\n",
       "      <td>575</td>\n",
       "      <td>477</td>\n",
       "      <td>1136</td>\n",
       "      <td>90</td>\n",
       "      <td>214</td>\n",
       "      <td>193</td>\n",
       "      <td>150</td>\n",
       "      <td>583</td>\n",
       "      <td>206</td>\n",
       "      <td>326</td>\n",
       "      <td>70</td>\n",
       "      <td>332</td>\n",
       "      <td>366</td>\n",
       "      <td>1071</td>\n",
       "      <td>685</td>\n",
       "      <td>422</td>\n",
       "      <td>441</td>\n",
       "      <td>502</td>\n",
       "      <td>560</td>\n",
       "      <td>500</td>\n",
       "      <td>77</td>\n",
       "      <td>391</td>\n",
       "      <td>118</td>\n",
       "      <td>400</td>\n",
       "      <td>436</td>\n",
       "      <td>1447</td>\n",
       "      <td>113</td>\n",
       "      <td>437</td>\n",
       "      <td>273</td>\n",
       "      <td>1151</td>\n",
       "      <td>368</td>\n",
       "      <td>145</td>\n",
       "      <td>928</td>\n",
       "      <td>883</td>\n",
       "      <td>600</td>\n",
       "      <td>1782</td>\n",
       "      <td>1776</td>\n",
       "      <td>1449</td>\n",
       "      <td>1092</td>\n",
       "      <td>610</td>\n",
       "      <td>164</td>\n",
       "      <td>786</td>\n",
       "      <td>491</td>\n",
       "      <td>140</td>\n",
       "      <td>919</td>\n",
       "      <td>1700</td>\n",
       "      <td>501</td>\n",
       "      <td>329</td>\n",
       "      <td>933</td>\n",
       "      <td>240</td>\n",
       "      <td>440</td>\n",
       "      <td>1054</td>\n",
       "      <td>815</td>\n",
       "      <td>175</td>\n",
       "      <td>853</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>19D</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>180</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10032</td>\n",
       "      <td>233</td>\n",
       "      <td>1395</td>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>1293</td>\n",
       "      <td>245</td>\n",
       "      <td>193</td>\n",
       "      <td>394</td>\n",
       "      <td>338</td>\n",
       "      <td>257</td>\n",
       "      <td>479</td>\n",
       "      <td>67</td>\n",
       "      <td>344</td>\n",
       "      <td>320</td>\n",
       "      <td>135</td>\n",
       "      <td>944</td>\n",
       "      <td>232</td>\n",
       "      <td>870</td>\n",
       "      <td>584</td>\n",
       "      <td>468</td>\n",
       "      <td>357</td>\n",
       "      <td>1471</td>\n",
       "      <td>269</td>\n",
       "      <td>1021</td>\n",
       "      <td>253</td>\n",
       "      <td>1244</td>\n",
       "      <td>851</td>\n",
       "      <td>615</td>\n",
       "      <td>376</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>781</td>\n",
       "      <td>98</td>\n",
       "      <td>263</td>\n",
       "      <td>348</td>\n",
       "      <td>289</td>\n",
       "      <td>523</td>\n",
       "      <td>476</td>\n",
       "      <td>1096</td>\n",
       "      <td>86</td>\n",
       "      <td>203</td>\n",
       "      <td>195</td>\n",
       "      <td>146</td>\n",
       "      <td>568</td>\n",
       "      <td>201</td>\n",
       "      <td>334</td>\n",
       "      <td>72</td>\n",
       "      <td>312</td>\n",
       "      <td>356</td>\n",
       "      <td>1046</td>\n",
       "      <td>620</td>\n",
       "      <td>441</td>\n",
       "      <td>447</td>\n",
       "      <td>490</td>\n",
       "      <td>540</td>\n",
       "      <td>488</td>\n",
       "      <td>73</td>\n",
       "      <td>371</td>\n",
       "      <td>131</td>\n",
       "      <td>380</td>\n",
       "      <td>420</td>\n",
       "      <td>1380</td>\n",
       "      <td>118</td>\n",
       "      <td>417</td>\n",
       "      <td>254</td>\n",
       "      <td>1119</td>\n",
       "      <td>353</td>\n",
       "      <td>141</td>\n",
       "      <td>884</td>\n",
       "      <td>868</td>\n",
       "      <td>564</td>\n",
       "      <td>1745</td>\n",
       "      <td>1702</td>\n",
       "      <td>1387</td>\n",
       "      <td>1076</td>\n",
       "      <td>572</td>\n",
       "      <td>169</td>\n",
       "      <td>822</td>\n",
       "      <td>476</td>\n",
       "      <td>120</td>\n",
       "      <td>918</td>\n",
       "      <td>1627</td>\n",
       "      <td>432</td>\n",
       "      <td>316</td>\n",
       "      <td>870</td>\n",
       "      <td>225</td>\n",
       "      <td>371</td>\n",
       "      <td>1054</td>\n",
       "      <td>726</td>\n",
       "      <td>167</td>\n",
       "      <td>815</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>160</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10033</td>\n",
       "      <td>287</td>\n",
       "      <td>1430</td>\n",
       "      <td>341</td>\n",
       "      <td>230</td>\n",
       "      <td>1327</td>\n",
       "      <td>256</td>\n",
       "      <td>196</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>261</td>\n",
       "      <td>544</td>\n",
       "      <td>75</td>\n",
       "      <td>345</td>\n",
       "      <td>330</td>\n",
       "      <td>135</td>\n",
       "      <td>1054</td>\n",
       "      <td>258</td>\n",
       "      <td>901</td>\n",
       "      <td>623</td>\n",
       "      <td>506</td>\n",
       "      <td>412</td>\n",
       "      <td>1501</td>\n",
       "      <td>288</td>\n",
       "      <td>1120</td>\n",
       "      <td>267</td>\n",
       "      <td>1288</td>\n",
       "      <td>854</td>\n",
       "      <td>636</td>\n",
       "      <td>359</td>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>237</td>\n",
       "      <td>810</td>\n",
       "      <td>103</td>\n",
       "      <td>270</td>\n",
       "      <td>355</td>\n",
       "      <td>357</td>\n",
       "      <td>575</td>\n",
       "      <td>491</td>\n",
       "      <td>1115</td>\n",
       "      <td>93</td>\n",
       "      <td>220</td>\n",
       "      <td>203</td>\n",
       "      <td>148</td>\n",
       "      <td>573</td>\n",
       "      <td>202</td>\n",
       "      <td>356</td>\n",
       "      <td>70</td>\n",
       "      <td>349</td>\n",
       "      <td>393</td>\n",
       "      <td>1053</td>\n",
       "      <td>665</td>\n",
       "      <td>462</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>556</td>\n",
       "      <td>482</td>\n",
       "      <td>72</td>\n",
       "      <td>409</td>\n",
       "      <td>123</td>\n",
       "      <td>403</td>\n",
       "      <td>434</td>\n",
       "      <td>1447</td>\n",
       "      <td>121</td>\n",
       "      <td>431</td>\n",
       "      <td>268</td>\n",
       "      <td>1276</td>\n",
       "      <td>367</td>\n",
       "      <td>167</td>\n",
       "      <td>917</td>\n",
       "      <td>910</td>\n",
       "      <td>604</td>\n",
       "      <td>1867</td>\n",
       "      <td>1735</td>\n",
       "      <td>1438</td>\n",
       "      <td>1105</td>\n",
       "      <td>685</td>\n",
       "      <td>198</td>\n",
       "      <td>807</td>\n",
       "      <td>477</td>\n",
       "      <td>125</td>\n",
       "      <td>918</td>\n",
       "      <td>1678</td>\n",
       "      <td>472</td>\n",
       "      <td>329</td>\n",
       "      <td>964</td>\n",
       "      <td>255</td>\n",
       "      <td>411</td>\n",
       "      <td>1041</td>\n",
       "      <td>929</td>\n",
       "      <td>180</td>\n",
       "      <td>831</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>205</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10092</td>\n",
       "      <td>234</td>\n",
       "      <td>1347</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>1239</td>\n",
       "      <td>262</td>\n",
       "      <td>199</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>262</td>\n",
       "      <td>518</td>\n",
       "      <td>73</td>\n",
       "      <td>328</td>\n",
       "      <td>309</td>\n",
       "      <td>143</td>\n",
       "      <td>991</td>\n",
       "      <td>242</td>\n",
       "      <td>821</td>\n",
       "      <td>560</td>\n",
       "      <td>437</td>\n",
       "      <td>395</td>\n",
       "      <td>1423</td>\n",
       "      <td>296</td>\n",
       "      <td>1114</td>\n",
       "      <td>262</td>\n",
       "      <td>1205</td>\n",
       "      <td>769</td>\n",
       "      <td>590</td>\n",
       "      <td>341</td>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>272</td>\n",
       "      <td>794</td>\n",
       "      <td>106</td>\n",
       "      <td>267</td>\n",
       "      <td>352</td>\n",
       "      <td>318</td>\n",
       "      <td>593</td>\n",
       "      <td>467</td>\n",
       "      <td>1034</td>\n",
       "      <td>91</td>\n",
       "      <td>217</td>\n",
       "      <td>194</td>\n",
       "      <td>158</td>\n",
       "      <td>576</td>\n",
       "      <td>199</td>\n",
       "      <td>341</td>\n",
       "      <td>68</td>\n",
       "      <td>338</td>\n",
       "      <td>367</td>\n",
       "      <td>986</td>\n",
       "      <td>640</td>\n",
       "      <td>458</td>\n",
       "      <td>461</td>\n",
       "      <td>460</td>\n",
       "      <td>511</td>\n",
       "      <td>452</td>\n",
       "      <td>76</td>\n",
       "      <td>393</td>\n",
       "      <td>106</td>\n",
       "      <td>407</td>\n",
       "      <td>446</td>\n",
       "      <td>1357</td>\n",
       "      <td>118</td>\n",
       "      <td>393</td>\n",
       "      <td>249</td>\n",
       "      <td>1155</td>\n",
       "      <td>330</td>\n",
       "      <td>148</td>\n",
       "      <td>903</td>\n",
       "      <td>848</td>\n",
       "      <td>550</td>\n",
       "      <td>1708</td>\n",
       "      <td>1655</td>\n",
       "      <td>1346</td>\n",
       "      <td>1021</td>\n",
       "      <td>604</td>\n",
       "      <td>180</td>\n",
       "      <td>803</td>\n",
       "      <td>445</td>\n",
       "      <td>127</td>\n",
       "      <td>847</td>\n",
       "      <td>1625</td>\n",
       "      <td>461</td>\n",
       "      <td>315</td>\n",
       "      <td>857</td>\n",
       "      <td>205</td>\n",
       "      <td>399</td>\n",
       "      <td>968</td>\n",
       "      <td>794</td>\n",
       "      <td>176</td>\n",
       "      <td>793</td>\n",
       "      <td>Male</td>\n",
       "      <td>12-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>88M</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10093</td>\n",
       "      <td>250</td>\n",
       "      <td>1585</td>\n",
       "      <td>372</td>\n",
       "      <td>247</td>\n",
       "      <td>1478</td>\n",
       "      <td>267</td>\n",
       "      <td>224</td>\n",
       "      <td>435</td>\n",
       "      <td>356</td>\n",
       "      <td>263</td>\n",
       "      <td>524</td>\n",
       "      <td>80</td>\n",
       "      <td>340</td>\n",
       "      <td>310</td>\n",
       "      <td>138</td>\n",
       "      <td>1029</td>\n",
       "      <td>275</td>\n",
       "      <td>1080</td>\n",
       "      <td>706</td>\n",
       "      <td>567</td>\n",
       "      <td>425</td>\n",
       "      <td>1684</td>\n",
       "      <td>304</td>\n",
       "      <td>1048</td>\n",
       "      <td>232</td>\n",
       "      <td>1452</td>\n",
       "      <td>1014</td>\n",
       "      <td>682</td>\n",
       "      <td>382</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>814</td>\n",
       "      <td>111</td>\n",
       "      <td>305</td>\n",
       "      <td>399</td>\n",
       "      <td>324</td>\n",
       "      <td>605</td>\n",
       "      <td>550</td>\n",
       "      <td>1279</td>\n",
       "      <td>94</td>\n",
       "      <td>222</td>\n",
       "      <td>218</td>\n",
       "      <td>153</td>\n",
       "      <td>566</td>\n",
       "      <td>197</td>\n",
       "      <td>374</td>\n",
       "      <td>69</td>\n",
       "      <td>332</td>\n",
       "      <td>372</td>\n",
       "      <td>1251</td>\n",
       "      <td>675</td>\n",
       "      <td>481</td>\n",
       "      <td>505</td>\n",
       "      <td>612</td>\n",
       "      <td>666</td>\n",
       "      <td>585</td>\n",
       "      <td>85</td>\n",
       "      <td>458</td>\n",
       "      <td>135</td>\n",
       "      <td>398</td>\n",
       "      <td>430</td>\n",
       "      <td>1572</td>\n",
       "      <td>132</td>\n",
       "      <td>523</td>\n",
       "      <td>302</td>\n",
       "      <td>1231</td>\n",
       "      <td>400</td>\n",
       "      <td>180</td>\n",
       "      <td>919</td>\n",
       "      <td>995</td>\n",
       "      <td>641</td>\n",
       "      <td>2035</td>\n",
       "      <td>1914</td>\n",
       "      <td>1596</td>\n",
       "      <td>1292</td>\n",
       "      <td>672</td>\n",
       "      <td>194</td>\n",
       "      <td>962</td>\n",
       "      <td>584</td>\n",
       "      <td>122</td>\n",
       "      <td>1090</td>\n",
       "      <td>1679</td>\n",
       "      <td>467</td>\n",
       "      <td>303</td>\n",
       "      <td>868</td>\n",
       "      <td>214</td>\n",
       "      <td>379</td>\n",
       "      <td>1245</td>\n",
       "      <td>946</td>\n",
       "      <td>188</td>\n",
       "      <td>954</td>\n",
       "      <td>Male</td>\n",
       "      <td>12-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>92G</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectid  abdominalextensiondepthsitting  acromialheight  \\\n",
       "0      10027                             266            1467   \n",
       "1      10032                             233            1395   \n",
       "2      10033                             287            1430   \n",
       "3      10092                             234            1347   \n",
       "4      10093                             250            1585   \n",
       "\n",
       "   acromionradialelength  anklecircumference  axillaheight  \\\n",
       "0                    337                 222          1347   \n",
       "1                    326                 220          1293   \n",
       "2                    341                 230          1327   \n",
       "3                    310                 230          1239   \n",
       "4                    372                 247          1478   \n",
       "\n",
       "   balloffootcircumference  balloffootlength  biacromialbreadth  \\\n",
       "0                      253               202                401   \n",
       "1                      245               193                394   \n",
       "2                      256               196                427   \n",
       "3                      262               199                401   \n",
       "4                      267               224                435   \n",
       "\n",
       "   bicepscircumferenceflexed  bicristalbreadth  bideltoidbreadth  \\\n",
       "0                        369               274               493   \n",
       "1                        338               257               479   \n",
       "2                        408               261               544   \n",
       "3                        359               262               518   \n",
       "4                        356               263               524   \n",
       "\n",
       "   bimalleolarbreadth  bitragionchinarc  bitragionsubmandibulararc  \\\n",
       "0                  71               319                        291   \n",
       "1                  67               344                        320   \n",
       "2                  75               345                        330   \n",
       "3                  73               328                        309   \n",
       "4                  80               340                        310   \n",
       "\n",
       "   bizygomaticbreadth  buttockcircumference  buttockdepth  buttockheight  \\\n",
       "0                 142                   979           240            882   \n",
       "1                 135                   944           232            870   \n",
       "2                 135                  1054           258            901   \n",
       "3                 143                   991           242            821   \n",
       "4                 138                  1029           275           1080   \n",
       "\n",
       "   buttockkneelength  buttockpopliteallength  calfcircumference  \\\n",
       "0                619                     509                373   \n",
       "1                584                     468                357   \n",
       "2                623                     506                412   \n",
       "3                560                     437                395   \n",
       "4                706                     567                425   \n",
       "\n",
       "   cervicaleheight  chestbreadth  chestcircumference  chestdepth  chestheight  \\\n",
       "0             1535           291                1074         259         1292   \n",
       "1             1471           269                1021         253         1244   \n",
       "2             1501           288                1120         267         1288   \n",
       "3             1423           296                1114         262         1205   \n",
       "4             1684           304                1048         232         1452   \n",
       "\n",
       "   crotchheight  crotchlengthomphalion  crotchlengthposterioromphalion  \\\n",
       "0           877                    607                             351   \n",
       "1           851                    615                             376   \n",
       "2           854                    636                             359   \n",
       "3           769                    590                             341   \n",
       "4          1014                    682                             382   \n",
       "\n",
       "   earbreadth  earlength  earprotrusion  elbowrestheight  eyeheightsitting  \\\n",
       "0          36         71             19              247               802   \n",
       "1          33         62             18              232               781   \n",
       "2          40         61             23              237               810   \n",
       "3          39         66             25              272               794   \n",
       "4          32         56             19              188               814   \n",
       "\n",
       "   footbreadthhorizontal  footlength  forearmcenterofgriplength  \\\n",
       "0                    101         273                        349   \n",
       "1                     98         263                        348   \n",
       "2                    103         270                        355   \n",
       "3                    106         267                        352   \n",
       "4                    111         305                        399   \n",
       "\n",
       "   forearmcircumferenceflexed  forearmforearmbreadth  forearmhandlength  \\\n",
       "0                         299                    575                477   \n",
       "1                         289                    523                476   \n",
       "2                         357                    575                491   \n",
       "3                         318                    593                467   \n",
       "4                         324                    605                550   \n",
       "\n",
       "   functionalleglength  handbreadth  handcircumference  handlength  \\\n",
       "0                 1136           90                214         193   \n",
       "1                 1096           86                203         195   \n",
       "2                 1115           93                220         203   \n",
       "3                 1034           91                217         194   \n",
       "4                 1279           94                222         218   \n",
       "\n",
       "   headbreadth  headcircumference  headlength  heelanklecircumference  \\\n",
       "0          150                583         206                     326   \n",
       "1          146                568         201                     334   \n",
       "2          148                573         202                     356   \n",
       "3          158                576         199                     341   \n",
       "4          153                566         197                     374   \n",
       "\n",
       "   heelbreadth  hipbreadth  hipbreadthsitting  iliocristaleheight  \\\n",
       "0           70         332                366                1071   \n",
       "1           72         312                356                1046   \n",
       "2           70         349                393                1053   \n",
       "3           68         338                367                 986   \n",
       "4           69         332                372                1251   \n",
       "\n",
       "   interpupillarybreadth  interscyei  interscyeii  kneeheightmidpatella  \\\n",
       "0                    685         422          441                   502   \n",
       "1                    620         441          447                   490   \n",
       "2                    665         462          475                   496   \n",
       "3                    640         458          461                   460   \n",
       "4                    675         481          505                   612   \n",
       "\n",
       "   kneeheightsitting  lateralfemoralepicondyleheight  lateralmalleolusheight  \\\n",
       "0                560                             500                      77   \n",
       "1                540                             488                      73   \n",
       "2                556                             482                      72   \n",
       "3                511                             452                      76   \n",
       "4                666                             585                      85   \n",
       "\n",
       "   lowerthighcircumference  mentonsellionlength  neckcircumference  \\\n",
       "0                      391                  118                400   \n",
       "1                      371                  131                380   \n",
       "2                      409                  123                403   \n",
       "3                      393                  106                407   \n",
       "4                      458                  135                398   \n",
       "\n",
       "   neckcircumferencebase  overheadfingertipreachsitting  palmlength  \\\n",
       "0                    436                           1447         113   \n",
       "1                    420                           1380         118   \n",
       "2                    434                           1447         121   \n",
       "3                    446                           1357         118   \n",
       "4                    430                           1572         132   \n",
       "\n",
       "   poplitealheight  radialestylionlength  shouldercircumference  \\\n",
       "0              437                   273                   1151   \n",
       "1              417                   254                   1119   \n",
       "2              431                   268                   1276   \n",
       "3              393                   249                   1155   \n",
       "4              523                   302                   1231   \n",
       "\n",
       "   shoulderelbowlength  shoulderlength  sittingheight  sleevelengthspinewrist  \\\n",
       "0                  368             145            928                     883   \n",
       "1                  353             141            884                     868   \n",
       "2                  367             167            917                     910   \n",
       "3                  330             148            903                     848   \n",
       "4                  400             180            919                     995   \n",
       "\n",
       "   sleeveoutseam  span  stature  suprasternaleheight  tenthribheight  \\\n",
       "0            600  1782     1776                 1449            1092   \n",
       "1            564  1745     1702                 1387            1076   \n",
       "2            604  1867     1735                 1438            1105   \n",
       "3            550  1708     1655                 1346            1021   \n",
       "4            641  2035     1914                 1596            1292   \n",
       "\n",
       "   thighcircumference  thighclearance  thumbtipreach  tibialheight  \\\n",
       "0                 610             164            786           491   \n",
       "1                 572             169            822           476   \n",
       "2                 685             198            807           477   \n",
       "3                 604             180            803           445   \n",
       "4                 672             194            962           584   \n",
       "\n",
       "   tragiontopofhead  trochanterionheight  verticaltrunkcircumferenceusa  \\\n",
       "0               140                  919                           1700   \n",
       "1               120                  918                           1627   \n",
       "2               125                  918                           1678   \n",
       "3               127                  847                           1625   \n",
       "4               122                 1090                           1679   \n",
       "\n",
       "   waistbacklength  waistbreadth  waistcircumference  waistdepth  \\\n",
       "0              501           329                 933         240   \n",
       "1              432           316                 870         225   \n",
       "2              472           329                 964         255   \n",
       "3              461           315                 857         205   \n",
       "4              467           303                 868         214   \n",
       "\n",
       "   waistfrontlengthsitting  waistheightomphalion  weightkg  \\\n",
       "0                      440                  1054       815   \n",
       "1                      371                  1054       726   \n",
       "2                      411                  1041       929   \n",
       "3                      399                   968       794   \n",
       "4                      379                  1245       946   \n",
       "\n",
       "   wristcircumference  wristheight Gender       Date Installation  \\\n",
       "0                 175          853   Male   4-Oct-10    Fort Hood   \n",
       "1                 167          815   Male   4-Oct-10    Fort Hood   \n",
       "2                 180          831   Male   4-Oct-10    Fort Hood   \n",
       "3                 176          793   Male  12-Oct-10    Fort Hood   \n",
       "4                 188          954   Male  12-Oct-10    Fort Hood   \n",
       "\n",
       "      Component                  Branch PrimaryMOS SubjectsBirthLocation  \\\n",
       "0  Regular Army             Combat Arms        19D          North Dakota   \n",
       "1  Regular Army          Combat Support        68W              New York   \n",
       "2  Regular Army          Combat Support        68W              New York   \n",
       "3  Regular Army  Combat Service Support        88M             Wisconsin   \n",
       "4  Regular Army  Combat Service Support        92G        North Carolina   \n",
       "\n",
       "   SubjectNumericRace Ethnicity  DODRace  Age  Heightin  Weightlbs  \\\n",
       "0                   1       NaN        1   41        71        180   \n",
       "1                   1       NaN        1   35        68        160   \n",
       "2                   2       NaN        2   42        68        205   \n",
       "3                   1       NaN        1   31        66        175   \n",
       "4                   2       NaN        2   21        77        213   \n",
       "\n",
       "  WritingPreference  \n",
       "0        Right hand  \n",
       "1         Left hand  \n",
       "2         Left hand  \n",
       "3        Right hand  \n",
       "4        Right hand  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>bideltoidbreadth</th>\n",
       "      <th>bimalleolarbreadth</th>\n",
       "      <th>bitragionchinarc</th>\n",
       "      <th>bitragionsubmandibulararc</th>\n",
       "      <th>bizygomaticbreadth</th>\n",
       "      <th>buttockcircumference</th>\n",
       "      <th>buttockdepth</th>\n",
       "      <th>buttockheight</th>\n",
       "      <th>buttockkneelength</th>\n",
       "      <th>buttockpopliteallength</th>\n",
       "      <th>calfcircumference</th>\n",
       "      <th>cervicaleheight</th>\n",
       "      <th>chestbreadth</th>\n",
       "      <th>chestcircumference</th>\n",
       "      <th>chestdepth</th>\n",
       "      <th>chestheight</th>\n",
       "      <th>crotchheight</th>\n",
       "      <th>crotchlengthomphalion</th>\n",
       "      <th>crotchlengthposterioromphalion</th>\n",
       "      <th>earbreadth</th>\n",
       "      <th>earlength</th>\n",
       "      <th>earprotrusion</th>\n",
       "      <th>elbowrestheight</th>\n",
       "      <th>eyeheightsitting</th>\n",
       "      <th>footbreadthhorizontal</th>\n",
       "      <th>footlength</th>\n",
       "      <th>forearmcenterofgriplength</th>\n",
       "      <th>forearmcircumferenceflexed</th>\n",
       "      <th>forearmforearmbreadth</th>\n",
       "      <th>forearmhandlength</th>\n",
       "      <th>functionalleglength</th>\n",
       "      <th>handbreadth</th>\n",
       "      <th>handcircumference</th>\n",
       "      <th>handlength</th>\n",
       "      <th>headbreadth</th>\n",
       "      <th>headcircumference</th>\n",
       "      <th>headlength</th>\n",
       "      <th>heelanklecircumference</th>\n",
       "      <th>heelbreadth</th>\n",
       "      <th>hipbreadth</th>\n",
       "      <th>hipbreadthsitting</th>\n",
       "      <th>iliocristaleheight</th>\n",
       "      <th>interpupillarybreadth</th>\n",
       "      <th>interscyei</th>\n",
       "      <th>interscyeii</th>\n",
       "      <th>kneeheightmidpatella</th>\n",
       "      <th>kneeheightsitting</th>\n",
       "      <th>lateralfemoralepicondyleheight</th>\n",
       "      <th>lateralmalleolusheight</th>\n",
       "      <th>lowerthighcircumference</th>\n",
       "      <th>mentonsellionlength</th>\n",
       "      <th>neckcircumference</th>\n",
       "      <th>neckcircumferencebase</th>\n",
       "      <th>overheadfingertipreachsitting</th>\n",
       "      <th>palmlength</th>\n",
       "      <th>poplitealheight</th>\n",
       "      <th>radialestylionlength</th>\n",
       "      <th>shouldercircumference</th>\n",
       "      <th>shoulderelbowlength</th>\n",
       "      <th>shoulderlength</th>\n",
       "      <th>sittingheight</th>\n",
       "      <th>sleevelengthspinewrist</th>\n",
       "      <th>sleeveoutseam</th>\n",
       "      <th>span</th>\n",
       "      <th>stature</th>\n",
       "      <th>suprasternaleheight</th>\n",
       "      <th>tenthribheight</th>\n",
       "      <th>thighcircumference</th>\n",
       "      <th>thighclearance</th>\n",
       "      <th>thumbtipreach</th>\n",
       "      <th>tibialheight</th>\n",
       "      <th>tragiontopofhead</th>\n",
       "      <th>trochanterionheight</th>\n",
       "      <th>verticaltrunkcircumferenceusa</th>\n",
       "      <th>waistbacklength</th>\n",
       "      <th>waistbreadth</th>\n",
       "      <th>waistcircumference</th>\n",
       "      <th>waistdepth</th>\n",
       "      <th>waistfrontlengthsitting</th>\n",
       "      <th>waistheightomphalion</th>\n",
       "      <th>weightkg</th>\n",
       "      <th>wristcircumference</th>\n",
       "      <th>wristheight</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Component</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10037</td>\n",
       "      <td>231</td>\n",
       "      <td>1282</td>\n",
       "      <td>301</td>\n",
       "      <td>204</td>\n",
       "      <td>1180</td>\n",
       "      <td>222</td>\n",
       "      <td>177</td>\n",
       "      <td>373</td>\n",
       "      <td>315</td>\n",
       "      <td>263</td>\n",
       "      <td>466</td>\n",
       "      <td>65</td>\n",
       "      <td>338</td>\n",
       "      <td>301</td>\n",
       "      <td>141</td>\n",
       "      <td>1011</td>\n",
       "      <td>223</td>\n",
       "      <td>836</td>\n",
       "      <td>587</td>\n",
       "      <td>476</td>\n",
       "      <td>360</td>\n",
       "      <td>1336</td>\n",
       "      <td>274</td>\n",
       "      <td>922</td>\n",
       "      <td>245</td>\n",
       "      <td>1095</td>\n",
       "      <td>759</td>\n",
       "      <td>557</td>\n",
       "      <td>310</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>220</td>\n",
       "      <td>713</td>\n",
       "      <td>91</td>\n",
       "      <td>246</td>\n",
       "      <td>316</td>\n",
       "      <td>265</td>\n",
       "      <td>517</td>\n",
       "      <td>432</td>\n",
       "      <td>1028</td>\n",
       "      <td>75</td>\n",
       "      <td>182</td>\n",
       "      <td>184</td>\n",
       "      <td>141</td>\n",
       "      <td>548</td>\n",
       "      <td>191</td>\n",
       "      <td>314</td>\n",
       "      <td>69</td>\n",
       "      <td>345</td>\n",
       "      <td>388</td>\n",
       "      <td>966</td>\n",
       "      <td>645</td>\n",
       "      <td>363</td>\n",
       "      <td>399</td>\n",
       "      <td>435</td>\n",
       "      <td>496</td>\n",
       "      <td>447</td>\n",
       "      <td>55</td>\n",
       "      <td>404</td>\n",
       "      <td>118</td>\n",
       "      <td>335</td>\n",
       "      <td>368</td>\n",
       "      <td>1268</td>\n",
       "      <td>113</td>\n",
       "      <td>362</td>\n",
       "      <td>235</td>\n",
       "      <td>1062</td>\n",
       "      <td>327</td>\n",
       "      <td>148</td>\n",
       "      <td>803</td>\n",
       "      <td>809</td>\n",
       "      <td>513</td>\n",
       "      <td>1647</td>\n",
       "      <td>1560</td>\n",
       "      <td>1280</td>\n",
       "      <td>1013</td>\n",
       "      <td>622</td>\n",
       "      <td>174</td>\n",
       "      <td>736</td>\n",
       "      <td>430</td>\n",
       "      <td>110</td>\n",
       "      <td>844</td>\n",
       "      <td>1488</td>\n",
       "      <td>406</td>\n",
       "      <td>295</td>\n",
       "      <td>850</td>\n",
       "      <td>217</td>\n",
       "      <td>345</td>\n",
       "      <td>942</td>\n",
       "      <td>657</td>\n",
       "      <td>152</td>\n",
       "      <td>756</td>\n",
       "      <td>Female</td>\n",
       "      <td>5-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>92Y</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>142</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10038</td>\n",
       "      <td>194</td>\n",
       "      <td>1379</td>\n",
       "      <td>320</td>\n",
       "      <td>207</td>\n",
       "      <td>1292</td>\n",
       "      <td>225</td>\n",
       "      <td>178</td>\n",
       "      <td>372</td>\n",
       "      <td>272</td>\n",
       "      <td>250</td>\n",
       "      <td>430</td>\n",
       "      <td>64</td>\n",
       "      <td>294</td>\n",
       "      <td>270</td>\n",
       "      <td>126</td>\n",
       "      <td>893</td>\n",
       "      <td>186</td>\n",
       "      <td>900</td>\n",
       "      <td>583</td>\n",
       "      <td>483</td>\n",
       "      <td>350</td>\n",
       "      <td>1440</td>\n",
       "      <td>261</td>\n",
       "      <td>839</td>\n",
       "      <td>206</td>\n",
       "      <td>1234</td>\n",
       "      <td>835</td>\n",
       "      <td>549</td>\n",
       "      <td>329</td>\n",
       "      <td>32</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>208</td>\n",
       "      <td>726</td>\n",
       "      <td>91</td>\n",
       "      <td>249</td>\n",
       "      <td>341</td>\n",
       "      <td>247</td>\n",
       "      <td>468</td>\n",
       "      <td>463</td>\n",
       "      <td>1117</td>\n",
       "      <td>78</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>138</td>\n",
       "      <td>535</td>\n",
       "      <td>180</td>\n",
       "      <td>307</td>\n",
       "      <td>60</td>\n",
       "      <td>315</td>\n",
       "      <td>335</td>\n",
       "      <td>1048</td>\n",
       "      <td>595</td>\n",
       "      <td>340</td>\n",
       "      <td>375</td>\n",
       "      <td>483</td>\n",
       "      <td>532</td>\n",
       "      <td>492</td>\n",
       "      <td>69</td>\n",
       "      <td>334</td>\n",
       "      <td>115</td>\n",
       "      <td>302</td>\n",
       "      <td>345</td>\n",
       "      <td>1389</td>\n",
       "      <td>110</td>\n",
       "      <td>426</td>\n",
       "      <td>259</td>\n",
       "      <td>1014</td>\n",
       "      <td>346</td>\n",
       "      <td>142</td>\n",
       "      <td>835</td>\n",
       "      <td>810</td>\n",
       "      <td>575</td>\n",
       "      <td>1751</td>\n",
       "      <td>1665</td>\n",
       "      <td>1372</td>\n",
       "      <td>1107</td>\n",
       "      <td>524</td>\n",
       "      <td>152</td>\n",
       "      <td>771</td>\n",
       "      <td>475</td>\n",
       "      <td>125</td>\n",
       "      <td>901</td>\n",
       "      <td>1470</td>\n",
       "      <td>422</td>\n",
       "      <td>254</td>\n",
       "      <td>708</td>\n",
       "      <td>168</td>\n",
       "      <td>329</td>\n",
       "      <td>1032</td>\n",
       "      <td>534</td>\n",
       "      <td>155</td>\n",
       "      <td>815</td>\n",
       "      <td>Female</td>\n",
       "      <td>5-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>25U</td>\n",
       "      <td>California</td>\n",
       "      <td>3</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10042</td>\n",
       "      <td>183</td>\n",
       "      <td>1369</td>\n",
       "      <td>329</td>\n",
       "      <td>233</td>\n",
       "      <td>1271</td>\n",
       "      <td>237</td>\n",
       "      <td>196</td>\n",
       "      <td>397</td>\n",
       "      <td>300</td>\n",
       "      <td>276</td>\n",
       "      <td>450</td>\n",
       "      <td>69</td>\n",
       "      <td>309</td>\n",
       "      <td>270</td>\n",
       "      <td>128</td>\n",
       "      <td>987</td>\n",
       "      <td>204</td>\n",
       "      <td>861</td>\n",
       "      <td>583</td>\n",
       "      <td>466</td>\n",
       "      <td>384</td>\n",
       "      <td>1451</td>\n",
       "      <td>287</td>\n",
       "      <td>874</td>\n",
       "      <td>223</td>\n",
       "      <td>1226</td>\n",
       "      <td>821</td>\n",
       "      <td>643</td>\n",
       "      <td>374</td>\n",
       "      <td>36</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>204</td>\n",
       "      <td>790</td>\n",
       "      <td>100</td>\n",
       "      <td>265</td>\n",
       "      <td>343</td>\n",
       "      <td>262</td>\n",
       "      <td>488</td>\n",
       "      <td>469</td>\n",
       "      <td>1060</td>\n",
       "      <td>84</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>146</td>\n",
       "      <td>588</td>\n",
       "      <td>207</td>\n",
       "      <td>331</td>\n",
       "      <td>70</td>\n",
       "      <td>356</td>\n",
       "      <td>399</td>\n",
       "      <td>1043</td>\n",
       "      <td>655</td>\n",
       "      <td>345</td>\n",
       "      <td>399</td>\n",
       "      <td>470</td>\n",
       "      <td>530</td>\n",
       "      <td>469</td>\n",
       "      <td>64</td>\n",
       "      <td>401</td>\n",
       "      <td>135</td>\n",
       "      <td>325</td>\n",
       "      <td>369</td>\n",
       "      <td>1414</td>\n",
       "      <td>122</td>\n",
       "      <td>398</td>\n",
       "      <td>258</td>\n",
       "      <td>1049</td>\n",
       "      <td>362</td>\n",
       "      <td>164</td>\n",
       "      <td>904</td>\n",
       "      <td>855</td>\n",
       "      <td>568</td>\n",
       "      <td>1779</td>\n",
       "      <td>1711</td>\n",
       "      <td>1383</td>\n",
       "      <td>1089</td>\n",
       "      <td>577</td>\n",
       "      <td>164</td>\n",
       "      <td>814</td>\n",
       "      <td>458</td>\n",
       "      <td>129</td>\n",
       "      <td>882</td>\n",
       "      <td>1542</td>\n",
       "      <td>419</td>\n",
       "      <td>269</td>\n",
       "      <td>727</td>\n",
       "      <td>159</td>\n",
       "      <td>367</td>\n",
       "      <td>1035</td>\n",
       "      <td>663</td>\n",
       "      <td>162</td>\n",
       "      <td>799</td>\n",
       "      <td>Female</td>\n",
       "      <td>5-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>35D</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>68</td>\n",
       "      <td>147</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10043</td>\n",
       "      <td>261</td>\n",
       "      <td>1356</td>\n",
       "      <td>306</td>\n",
       "      <td>214</td>\n",
       "      <td>1250</td>\n",
       "      <td>240</td>\n",
       "      <td>188</td>\n",
       "      <td>384</td>\n",
       "      <td>364</td>\n",
       "      <td>276</td>\n",
       "      <td>484</td>\n",
       "      <td>68</td>\n",
       "      <td>340</td>\n",
       "      <td>294</td>\n",
       "      <td>144</td>\n",
       "      <td>1012</td>\n",
       "      <td>253</td>\n",
       "      <td>897</td>\n",
       "      <td>599</td>\n",
       "      <td>471</td>\n",
       "      <td>372</td>\n",
       "      <td>1430</td>\n",
       "      <td>269</td>\n",
       "      <td>1008</td>\n",
       "      <td>285</td>\n",
       "      <td>1170</td>\n",
       "      <td>804</td>\n",
       "      <td>640</td>\n",
       "      <td>351</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>22</td>\n",
       "      <td>244</td>\n",
       "      <td>775</td>\n",
       "      <td>97</td>\n",
       "      <td>265</td>\n",
       "      <td>331</td>\n",
       "      <td>309</td>\n",
       "      <td>529</td>\n",
       "      <td>455</td>\n",
       "      <td>1069</td>\n",
       "      <td>80</td>\n",
       "      <td>192</td>\n",
       "      <td>186</td>\n",
       "      <td>153</td>\n",
       "      <td>593</td>\n",
       "      <td>206</td>\n",
       "      <td>332</td>\n",
       "      <td>68</td>\n",
       "      <td>337</td>\n",
       "      <td>402</td>\n",
       "      <td>1029</td>\n",
       "      <td>655</td>\n",
       "      <td>392</td>\n",
       "      <td>435</td>\n",
       "      <td>469</td>\n",
       "      <td>520</td>\n",
       "      <td>478</td>\n",
       "      <td>67</td>\n",
       "      <td>402</td>\n",
       "      <td>118</td>\n",
       "      <td>357</td>\n",
       "      <td>386</td>\n",
       "      <td>1329</td>\n",
       "      <td>115</td>\n",
       "      <td>394</td>\n",
       "      <td>250</td>\n",
       "      <td>1121</td>\n",
       "      <td>333</td>\n",
       "      <td>157</td>\n",
       "      <td>875</td>\n",
       "      <td>815</td>\n",
       "      <td>536</td>\n",
       "      <td>1708</td>\n",
       "      <td>1660</td>\n",
       "      <td>1358</td>\n",
       "      <td>1065</td>\n",
       "      <td>679</td>\n",
       "      <td>187</td>\n",
       "      <td>736</td>\n",
       "      <td>463</td>\n",
       "      <td>125</td>\n",
       "      <td>866</td>\n",
       "      <td>1627</td>\n",
       "      <td>451</td>\n",
       "      <td>302</td>\n",
       "      <td>923</td>\n",
       "      <td>235</td>\n",
       "      <td>371</td>\n",
       "      <td>999</td>\n",
       "      <td>782</td>\n",
       "      <td>173</td>\n",
       "      <td>818</td>\n",
       "      <td>Female</td>\n",
       "      <td>5-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>25U</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>8</td>\n",
       "      <td>Caribbean Islander</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10051</td>\n",
       "      <td>309</td>\n",
       "      <td>1303</td>\n",
       "      <td>308</td>\n",
       "      <td>214</td>\n",
       "      <td>1210</td>\n",
       "      <td>217</td>\n",
       "      <td>182</td>\n",
       "      <td>378</td>\n",
       "      <td>320</td>\n",
       "      <td>336</td>\n",
       "      <td>525</td>\n",
       "      <td>67</td>\n",
       "      <td>300</td>\n",
       "      <td>295</td>\n",
       "      <td>135</td>\n",
       "      <td>1281</td>\n",
       "      <td>284</td>\n",
       "      <td>811</td>\n",
       "      <td>607</td>\n",
       "      <td>467</td>\n",
       "      <td>433</td>\n",
       "      <td>1362</td>\n",
       "      <td>305</td>\n",
       "      <td>1089</td>\n",
       "      <td>290</td>\n",
       "      <td>1112</td>\n",
       "      <td>726</td>\n",
       "      <td>686</td>\n",
       "      <td>356</td>\n",
       "      <td>34</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>233</td>\n",
       "      <td>732</td>\n",
       "      <td>88</td>\n",
       "      <td>247</td>\n",
       "      <td>339</td>\n",
       "      <td>260</td>\n",
       "      <td>596</td>\n",
       "      <td>447</td>\n",
       "      <td>1039</td>\n",
       "      <td>78</td>\n",
       "      <td>183</td>\n",
       "      <td>187</td>\n",
       "      <td>140</td>\n",
       "      <td>522</td>\n",
       "      <td>181</td>\n",
       "      <td>308</td>\n",
       "      <td>63</td>\n",
       "      <td>448</td>\n",
       "      <td>499</td>\n",
       "      <td>964</td>\n",
       "      <td>635</td>\n",
       "      <td>428</td>\n",
       "      <td>435</td>\n",
       "      <td>440</td>\n",
       "      <td>491</td>\n",
       "      <td>441</td>\n",
       "      <td>63</td>\n",
       "      <td>479</td>\n",
       "      <td>114</td>\n",
       "      <td>340</td>\n",
       "      <td>358</td>\n",
       "      <td>1350</td>\n",
       "      <td>116</td>\n",
       "      <td>345</td>\n",
       "      <td>242</td>\n",
       "      <td>1151</td>\n",
       "      <td>329</td>\n",
       "      <td>156</td>\n",
       "      <td>824</td>\n",
       "      <td>810</td>\n",
       "      <td>559</td>\n",
       "      <td>1702</td>\n",
       "      <td>1572</td>\n",
       "      <td>1292</td>\n",
       "      <td>1030</td>\n",
       "      <td>766</td>\n",
       "      <td>197</td>\n",
       "      <td>766</td>\n",
       "      <td>429</td>\n",
       "      <td>116</td>\n",
       "      <td>800</td>\n",
       "      <td>1698</td>\n",
       "      <td>452</td>\n",
       "      <td>405</td>\n",
       "      <td>1163</td>\n",
       "      <td>300</td>\n",
       "      <td>380</td>\n",
       "      <td>911</td>\n",
       "      <td>886</td>\n",
       "      <td>152</td>\n",
       "      <td>762</td>\n",
       "      <td>Female</td>\n",
       "      <td>5-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>42A</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>195</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectId  abdominalextensiondepthsitting  acromialheight  \\\n",
       "0      10037                             231            1282   \n",
       "1      10038                             194            1379   \n",
       "2      10042                             183            1369   \n",
       "3      10043                             261            1356   \n",
       "4      10051                             309            1303   \n",
       "\n",
       "   acromionradialelength  anklecircumference  axillaheight  \\\n",
       "0                    301                 204          1180   \n",
       "1                    320                 207          1292   \n",
       "2                    329                 233          1271   \n",
       "3                    306                 214          1250   \n",
       "4                    308                 214          1210   \n",
       "\n",
       "   balloffootcircumference  balloffootlength  biacromialbreadth  \\\n",
       "0                      222               177                373   \n",
       "1                      225               178                372   \n",
       "2                      237               196                397   \n",
       "3                      240               188                384   \n",
       "4                      217               182                378   \n",
       "\n",
       "   bicepscircumferenceflexed  bicristalbreadth  bideltoidbreadth  \\\n",
       "0                        315               263               466   \n",
       "1                        272               250               430   \n",
       "2                        300               276               450   \n",
       "3                        364               276               484   \n",
       "4                        320               336               525   \n",
       "\n",
       "   bimalleolarbreadth  bitragionchinarc  bitragionsubmandibulararc  \\\n",
       "0                  65               338                        301   \n",
       "1                  64               294                        270   \n",
       "2                  69               309                        270   \n",
       "3                  68               340                        294   \n",
       "4                  67               300                        295   \n",
       "\n",
       "   bizygomaticbreadth  buttockcircumference  buttockdepth  buttockheight  \\\n",
       "0                 141                  1011           223            836   \n",
       "1                 126                   893           186            900   \n",
       "2                 128                   987           204            861   \n",
       "3                 144                  1012           253            897   \n",
       "4                 135                  1281           284            811   \n",
       "\n",
       "   buttockkneelength  buttockpopliteallength  calfcircumference  \\\n",
       "0                587                     476                360   \n",
       "1                583                     483                350   \n",
       "2                583                     466                384   \n",
       "3                599                     471                372   \n",
       "4                607                     467                433   \n",
       "\n",
       "   cervicaleheight  chestbreadth  chestcircumference  chestdepth  chestheight  \\\n",
       "0             1336           274                 922         245         1095   \n",
       "1             1440           261                 839         206         1234   \n",
       "2             1451           287                 874         223         1226   \n",
       "3             1430           269                1008         285         1170   \n",
       "4             1362           305                1089         290         1112   \n",
       "\n",
       "   crotchheight  crotchlengthomphalion  crotchlengthposterioromphalion  \\\n",
       "0           759                    557                             310   \n",
       "1           835                    549                             329   \n",
       "2           821                    643                             374   \n",
       "3           804                    640                             351   \n",
       "4           726                    686                             356   \n",
       "\n",
       "   earbreadth  earlength  earprotrusion  elbowrestheight  eyeheightsitting  \\\n",
       "0          35         65             16              220               713   \n",
       "1          32         60             23              208               726   \n",
       "2          36         65             26              204               790   \n",
       "3          38         62             22              244               775   \n",
       "4          34         65             18              233               732   \n",
       "\n",
       "   footbreadthhorizontal  footlength  forearmcenterofgriplength  \\\n",
       "0                     91         246                        316   \n",
       "1                     91         249                        341   \n",
       "2                    100         265                        343   \n",
       "3                     97         265                        331   \n",
       "4                     88         247                        339   \n",
       "\n",
       "   forearmcircumferenceflexed  forearmforearmbreadth  forearmhandlength  \\\n",
       "0                         265                    517                432   \n",
       "1                         247                    468                463   \n",
       "2                         262                    488                469   \n",
       "3                         309                    529                455   \n",
       "4                         260                    596                447   \n",
       "\n",
       "   functionalleglength  handbreadth  handcircumference  handlength  \\\n",
       "0                 1028           75                182         184   \n",
       "1                 1117           78                187         189   \n",
       "2                 1060           84                198         195   \n",
       "3                 1069           80                192         186   \n",
       "4                 1039           78                183         187   \n",
       "\n",
       "   headbreadth  headcircumference  headlength  heelanklecircumference  \\\n",
       "0          141                548         191                     314   \n",
       "1          138                535         180                     307   \n",
       "2          146                588         207                     331   \n",
       "3          153                593         206                     332   \n",
       "4          140                522         181                     308   \n",
       "\n",
       "   heelbreadth  hipbreadth  hipbreadthsitting  iliocristaleheight  \\\n",
       "0           69         345                388                 966   \n",
       "1           60         315                335                1048   \n",
       "2           70         356                399                1043   \n",
       "3           68         337                402                1029   \n",
       "4           63         448                499                 964   \n",
       "\n",
       "   interpupillarybreadth  interscyei  interscyeii  kneeheightmidpatella  \\\n",
       "0                    645         363          399                   435   \n",
       "1                    595         340          375                   483   \n",
       "2                    655         345          399                   470   \n",
       "3                    655         392          435                   469   \n",
       "4                    635         428          435                   440   \n",
       "\n",
       "   kneeheightsitting  lateralfemoralepicondyleheight  lateralmalleolusheight  \\\n",
       "0                496                             447                      55   \n",
       "1                532                             492                      69   \n",
       "2                530                             469                      64   \n",
       "3                520                             478                      67   \n",
       "4                491                             441                      63   \n",
       "\n",
       "   lowerthighcircumference  mentonsellionlength  neckcircumference  \\\n",
       "0                      404                  118                335   \n",
       "1                      334                  115                302   \n",
       "2                      401                  135                325   \n",
       "3                      402                  118                357   \n",
       "4                      479                  114                340   \n",
       "\n",
       "   neckcircumferencebase  overheadfingertipreachsitting  palmlength  \\\n",
       "0                    368                           1268         113   \n",
       "1                    345                           1389         110   \n",
       "2                    369                           1414         122   \n",
       "3                    386                           1329         115   \n",
       "4                    358                           1350         116   \n",
       "\n",
       "   poplitealheight  radialestylionlength  shouldercircumference  \\\n",
       "0              362                   235                   1062   \n",
       "1              426                   259                   1014   \n",
       "2              398                   258                   1049   \n",
       "3              394                   250                   1121   \n",
       "4              345                   242                   1151   \n",
       "\n",
       "   shoulderelbowlength  shoulderlength  sittingheight  sleevelengthspinewrist  \\\n",
       "0                  327             148            803                     809   \n",
       "1                  346             142            835                     810   \n",
       "2                  362             164            904                     855   \n",
       "3                  333             157            875                     815   \n",
       "4                  329             156            824                     810   \n",
       "\n",
       "   sleeveoutseam  span  stature  suprasternaleheight  tenthribheight  \\\n",
       "0            513  1647     1560                 1280            1013   \n",
       "1            575  1751     1665                 1372            1107   \n",
       "2            568  1779     1711                 1383            1089   \n",
       "3            536  1708     1660                 1358            1065   \n",
       "4            559  1702     1572                 1292            1030   \n",
       "\n",
       "   thighcircumference  thighclearance  thumbtipreach  tibialheight  \\\n",
       "0                 622             174            736           430   \n",
       "1                 524             152            771           475   \n",
       "2                 577             164            814           458   \n",
       "3                 679             187            736           463   \n",
       "4                 766             197            766           429   \n",
       "\n",
       "   tragiontopofhead  trochanterionheight  verticaltrunkcircumferenceusa  \\\n",
       "0               110                  844                           1488   \n",
       "1               125                  901                           1470   \n",
       "2               129                  882                           1542   \n",
       "3               125                  866                           1627   \n",
       "4               116                  800                           1698   \n",
       "\n",
       "   waistbacklength  waistbreadth  waistcircumference  waistdepth  \\\n",
       "0              406           295                 850         217   \n",
       "1              422           254                 708         168   \n",
       "2              419           269                 727         159   \n",
       "3              451           302                 923         235   \n",
       "4              452           405                1163         300   \n",
       "\n",
       "   waistfrontlengthsitting  waistheightomphalion  weightkg  \\\n",
       "0                      345                   942       657   \n",
       "1                      329                  1032       534   \n",
       "2                      367                  1035       663   \n",
       "3                      371                   999       782   \n",
       "4                      380                   911       886   \n",
       "\n",
       "   wristcircumference  wristheight  Gender      Date Installation  \\\n",
       "0                 152          756  Female  5-Oct-10    Fort Hood   \n",
       "1                 155          815  Female  5-Oct-10    Fort Hood   \n",
       "2                 162          799  Female  5-Oct-10    Fort Hood   \n",
       "3                 173          818  Female  5-Oct-10    Fort Hood   \n",
       "4                 152          762  Female  5-Oct-10    Fort Hood   \n",
       "\n",
       "      Component                  Branch PrimaryMOS SubjectsBirthLocation  \\\n",
       "0  Regular Army          Combat Support        92Y               Germany   \n",
       "1  Regular Army  Combat Service Support        25U            California   \n",
       "2  Regular Army  Combat Service Support        35D                 Texas   \n",
       "3  Regular Army  Combat Service Support        25U  District of Columbia   \n",
       "4  Regular Army             Combat Arms        42A                 Texas   \n",
       "\n",
       "   SubjectNumericRace           Ethnicity  DODRace  Age  Heightin  Weightlbs  \\\n",
       "0                   2                 NaN        2   26        61        142   \n",
       "1                   3             Mexican        3   21        64        120   \n",
       "2                   1                 NaN        1   23        68        147   \n",
       "3                   8  Caribbean Islander        2   22        66        175   \n",
       "4                   1                 NaN        1   45        63        195   \n",
       "\n",
       "  WritingPreference  \n",
       "0        Right hand  \n",
       "1        Right hand  \n",
       "2        Right hand  \n",
       "3        Right hand  \n",
       "4        Right hand  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_male,df_female], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4082, 108), (1986, 108), (6068, 109))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.shape, df_female.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectid</th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>bideltoidbreadth</th>\n",
       "      <th>bimalleolarbreadth</th>\n",
       "      <th>bitragionchinarc</th>\n",
       "      <th>bitragionsubmandibulararc</th>\n",
       "      <th>bizygomaticbreadth</th>\n",
       "      <th>buttockcircumference</th>\n",
       "      <th>buttockdepth</th>\n",
       "      <th>buttockheight</th>\n",
       "      <th>buttockkneelength</th>\n",
       "      <th>buttockpopliteallength</th>\n",
       "      <th>calfcircumference</th>\n",
       "      <th>cervicaleheight</th>\n",
       "      <th>chestbreadth</th>\n",
       "      <th>chestcircumference</th>\n",
       "      <th>chestdepth</th>\n",
       "      <th>chestheight</th>\n",
       "      <th>crotchheight</th>\n",
       "      <th>crotchlengthomphalion</th>\n",
       "      <th>crotchlengthposterioromphalion</th>\n",
       "      <th>earbreadth</th>\n",
       "      <th>earlength</th>\n",
       "      <th>earprotrusion</th>\n",
       "      <th>elbowrestheight</th>\n",
       "      <th>eyeheightsitting</th>\n",
       "      <th>footbreadthhorizontal</th>\n",
       "      <th>footlength</th>\n",
       "      <th>forearmcenterofgriplength</th>\n",
       "      <th>forearmcircumferenceflexed</th>\n",
       "      <th>forearmforearmbreadth</th>\n",
       "      <th>forearmhandlength</th>\n",
       "      <th>functionalleglength</th>\n",
       "      <th>handbreadth</th>\n",
       "      <th>handcircumference</th>\n",
       "      <th>handlength</th>\n",
       "      <th>headbreadth</th>\n",
       "      <th>headcircumference</th>\n",
       "      <th>headlength</th>\n",
       "      <th>heelanklecircumference</th>\n",
       "      <th>heelbreadth</th>\n",
       "      <th>hipbreadth</th>\n",
       "      <th>hipbreadthsitting</th>\n",
       "      <th>iliocristaleheight</th>\n",
       "      <th>interpupillarybreadth</th>\n",
       "      <th>interscyei</th>\n",
       "      <th>interscyeii</th>\n",
       "      <th>kneeheightmidpatella</th>\n",
       "      <th>kneeheightsitting</th>\n",
       "      <th>lateralfemoralepicondyleheight</th>\n",
       "      <th>lateralmalleolusheight</th>\n",
       "      <th>lowerthighcircumference</th>\n",
       "      <th>mentonsellionlength</th>\n",
       "      <th>neckcircumference</th>\n",
       "      <th>neckcircumferencebase</th>\n",
       "      <th>overheadfingertipreachsitting</th>\n",
       "      <th>palmlength</th>\n",
       "      <th>poplitealheight</th>\n",
       "      <th>radialestylionlength</th>\n",
       "      <th>shouldercircumference</th>\n",
       "      <th>shoulderelbowlength</th>\n",
       "      <th>shoulderlength</th>\n",
       "      <th>sittingheight</th>\n",
       "      <th>sleevelengthspinewrist</th>\n",
       "      <th>sleeveoutseam</th>\n",
       "      <th>span</th>\n",
       "      <th>stature</th>\n",
       "      <th>suprasternaleheight</th>\n",
       "      <th>tenthribheight</th>\n",
       "      <th>thighcircumference</th>\n",
       "      <th>thighclearance</th>\n",
       "      <th>thumbtipreach</th>\n",
       "      <th>tibialheight</th>\n",
       "      <th>tragiontopofhead</th>\n",
       "      <th>trochanterionheight</th>\n",
       "      <th>verticaltrunkcircumferenceusa</th>\n",
       "      <th>waistbacklength</th>\n",
       "      <th>waistbreadth</th>\n",
       "      <th>waistcircumference</th>\n",
       "      <th>waistdepth</th>\n",
       "      <th>waistfrontlengthsitting</th>\n",
       "      <th>waistheightomphalion</th>\n",
       "      <th>weightkg</th>\n",
       "      <th>wristcircumference</th>\n",
       "      <th>wristheight</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Component</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "      <th>SubjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027.000</td>\n",
       "      <td>266</td>\n",
       "      <td>1467</td>\n",
       "      <td>337</td>\n",
       "      <td>222</td>\n",
       "      <td>1347</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>274</td>\n",
       "      <td>493</td>\n",
       "      <td>71</td>\n",
       "      <td>319</td>\n",
       "      <td>291</td>\n",
       "      <td>142</td>\n",
       "      <td>979</td>\n",
       "      <td>240</td>\n",
       "      <td>882</td>\n",
       "      <td>619</td>\n",
       "      <td>509</td>\n",
       "      <td>373</td>\n",
       "      <td>1535</td>\n",
       "      <td>291</td>\n",
       "      <td>1074</td>\n",
       "      <td>259</td>\n",
       "      <td>1292</td>\n",
       "      <td>877</td>\n",
       "      <td>607</td>\n",
       "      <td>351</td>\n",
       "      <td>36</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>247</td>\n",
       "      <td>802</td>\n",
       "      <td>101</td>\n",
       "      <td>273</td>\n",
       "      <td>349</td>\n",
       "      <td>299</td>\n",
       "      <td>575</td>\n",
       "      <td>477</td>\n",
       "      <td>1136</td>\n",
       "      <td>90</td>\n",
       "      <td>214</td>\n",
       "      <td>193</td>\n",
       "      <td>150</td>\n",
       "      <td>583</td>\n",
       "      <td>206</td>\n",
       "      <td>326</td>\n",
       "      <td>70</td>\n",
       "      <td>332</td>\n",
       "      <td>366</td>\n",
       "      <td>1071</td>\n",
       "      <td>685</td>\n",
       "      <td>422</td>\n",
       "      <td>441</td>\n",
       "      <td>502</td>\n",
       "      <td>560</td>\n",
       "      <td>500</td>\n",
       "      <td>77</td>\n",
       "      <td>391</td>\n",
       "      <td>118</td>\n",
       "      <td>400</td>\n",
       "      <td>436</td>\n",
       "      <td>1447</td>\n",
       "      <td>113</td>\n",
       "      <td>437</td>\n",
       "      <td>273</td>\n",
       "      <td>1151</td>\n",
       "      <td>368</td>\n",
       "      <td>145</td>\n",
       "      <td>928</td>\n",
       "      <td>883</td>\n",
       "      <td>600</td>\n",
       "      <td>1782</td>\n",
       "      <td>1776</td>\n",
       "      <td>1449</td>\n",
       "      <td>1092</td>\n",
       "      <td>610</td>\n",
       "      <td>164</td>\n",
       "      <td>786</td>\n",
       "      <td>491</td>\n",
       "      <td>140</td>\n",
       "      <td>919</td>\n",
       "      <td>1700</td>\n",
       "      <td>501</td>\n",
       "      <td>329</td>\n",
       "      <td>933</td>\n",
       "      <td>240</td>\n",
       "      <td>440</td>\n",
       "      <td>1054</td>\n",
       "      <td>815</td>\n",
       "      <td>175</td>\n",
       "      <td>853</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>19D</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>180</td>\n",
       "      <td>Right hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10032.000</td>\n",
       "      <td>233</td>\n",
       "      <td>1395</td>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>1293</td>\n",
       "      <td>245</td>\n",
       "      <td>193</td>\n",
       "      <td>394</td>\n",
       "      <td>338</td>\n",
       "      <td>257</td>\n",
       "      <td>479</td>\n",
       "      <td>67</td>\n",
       "      <td>344</td>\n",
       "      <td>320</td>\n",
       "      <td>135</td>\n",
       "      <td>944</td>\n",
       "      <td>232</td>\n",
       "      <td>870</td>\n",
       "      <td>584</td>\n",
       "      <td>468</td>\n",
       "      <td>357</td>\n",
       "      <td>1471</td>\n",
       "      <td>269</td>\n",
       "      <td>1021</td>\n",
       "      <td>253</td>\n",
       "      <td>1244</td>\n",
       "      <td>851</td>\n",
       "      <td>615</td>\n",
       "      <td>376</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>781</td>\n",
       "      <td>98</td>\n",
       "      <td>263</td>\n",
       "      <td>348</td>\n",
       "      <td>289</td>\n",
       "      <td>523</td>\n",
       "      <td>476</td>\n",
       "      <td>1096</td>\n",
       "      <td>86</td>\n",
       "      <td>203</td>\n",
       "      <td>195</td>\n",
       "      <td>146</td>\n",
       "      <td>568</td>\n",
       "      <td>201</td>\n",
       "      <td>334</td>\n",
       "      <td>72</td>\n",
       "      <td>312</td>\n",
       "      <td>356</td>\n",
       "      <td>1046</td>\n",
       "      <td>620</td>\n",
       "      <td>441</td>\n",
       "      <td>447</td>\n",
       "      <td>490</td>\n",
       "      <td>540</td>\n",
       "      <td>488</td>\n",
       "      <td>73</td>\n",
       "      <td>371</td>\n",
       "      <td>131</td>\n",
       "      <td>380</td>\n",
       "      <td>420</td>\n",
       "      <td>1380</td>\n",
       "      <td>118</td>\n",
       "      <td>417</td>\n",
       "      <td>254</td>\n",
       "      <td>1119</td>\n",
       "      <td>353</td>\n",
       "      <td>141</td>\n",
       "      <td>884</td>\n",
       "      <td>868</td>\n",
       "      <td>564</td>\n",
       "      <td>1745</td>\n",
       "      <td>1702</td>\n",
       "      <td>1387</td>\n",
       "      <td>1076</td>\n",
       "      <td>572</td>\n",
       "      <td>169</td>\n",
       "      <td>822</td>\n",
       "      <td>476</td>\n",
       "      <td>120</td>\n",
       "      <td>918</td>\n",
       "      <td>1627</td>\n",
       "      <td>432</td>\n",
       "      <td>316</td>\n",
       "      <td>870</td>\n",
       "      <td>225</td>\n",
       "      <td>371</td>\n",
       "      <td>1054</td>\n",
       "      <td>726</td>\n",
       "      <td>167</td>\n",
       "      <td>815</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>160</td>\n",
       "      <td>Left hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10033.000</td>\n",
       "      <td>287</td>\n",
       "      <td>1430</td>\n",
       "      <td>341</td>\n",
       "      <td>230</td>\n",
       "      <td>1327</td>\n",
       "      <td>256</td>\n",
       "      <td>196</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>261</td>\n",
       "      <td>544</td>\n",
       "      <td>75</td>\n",
       "      <td>345</td>\n",
       "      <td>330</td>\n",
       "      <td>135</td>\n",
       "      <td>1054</td>\n",
       "      <td>258</td>\n",
       "      <td>901</td>\n",
       "      <td>623</td>\n",
       "      <td>506</td>\n",
       "      <td>412</td>\n",
       "      <td>1501</td>\n",
       "      <td>288</td>\n",
       "      <td>1120</td>\n",
       "      <td>267</td>\n",
       "      <td>1288</td>\n",
       "      <td>854</td>\n",
       "      <td>636</td>\n",
       "      <td>359</td>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>237</td>\n",
       "      <td>810</td>\n",
       "      <td>103</td>\n",
       "      <td>270</td>\n",
       "      <td>355</td>\n",
       "      <td>357</td>\n",
       "      <td>575</td>\n",
       "      <td>491</td>\n",
       "      <td>1115</td>\n",
       "      <td>93</td>\n",
       "      <td>220</td>\n",
       "      <td>203</td>\n",
       "      <td>148</td>\n",
       "      <td>573</td>\n",
       "      <td>202</td>\n",
       "      <td>356</td>\n",
       "      <td>70</td>\n",
       "      <td>349</td>\n",
       "      <td>393</td>\n",
       "      <td>1053</td>\n",
       "      <td>665</td>\n",
       "      <td>462</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>556</td>\n",
       "      <td>482</td>\n",
       "      <td>72</td>\n",
       "      <td>409</td>\n",
       "      <td>123</td>\n",
       "      <td>403</td>\n",
       "      <td>434</td>\n",
       "      <td>1447</td>\n",
       "      <td>121</td>\n",
       "      <td>431</td>\n",
       "      <td>268</td>\n",
       "      <td>1276</td>\n",
       "      <td>367</td>\n",
       "      <td>167</td>\n",
       "      <td>917</td>\n",
       "      <td>910</td>\n",
       "      <td>604</td>\n",
       "      <td>1867</td>\n",
       "      <td>1735</td>\n",
       "      <td>1438</td>\n",
       "      <td>1105</td>\n",
       "      <td>685</td>\n",
       "      <td>198</td>\n",
       "      <td>807</td>\n",
       "      <td>477</td>\n",
       "      <td>125</td>\n",
       "      <td>918</td>\n",
       "      <td>1678</td>\n",
       "      <td>472</td>\n",
       "      <td>329</td>\n",
       "      <td>964</td>\n",
       "      <td>255</td>\n",
       "      <td>411</td>\n",
       "      <td>1041</td>\n",
       "      <td>929</td>\n",
       "      <td>180</td>\n",
       "      <td>831</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>205</td>\n",
       "      <td>Left hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10092.000</td>\n",
       "      <td>234</td>\n",
       "      <td>1347</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>1239</td>\n",
       "      <td>262</td>\n",
       "      <td>199</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>262</td>\n",
       "      <td>518</td>\n",
       "      <td>73</td>\n",
       "      <td>328</td>\n",
       "      <td>309</td>\n",
       "      <td>143</td>\n",
       "      <td>991</td>\n",
       "      <td>242</td>\n",
       "      <td>821</td>\n",
       "      <td>560</td>\n",
       "      <td>437</td>\n",
       "      <td>395</td>\n",
       "      <td>1423</td>\n",
       "      <td>296</td>\n",
       "      <td>1114</td>\n",
       "      <td>262</td>\n",
       "      <td>1205</td>\n",
       "      <td>769</td>\n",
       "      <td>590</td>\n",
       "      <td>341</td>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>272</td>\n",
       "      <td>794</td>\n",
       "      <td>106</td>\n",
       "      <td>267</td>\n",
       "      <td>352</td>\n",
       "      <td>318</td>\n",
       "      <td>593</td>\n",
       "      <td>467</td>\n",
       "      <td>1034</td>\n",
       "      <td>91</td>\n",
       "      <td>217</td>\n",
       "      <td>194</td>\n",
       "      <td>158</td>\n",
       "      <td>576</td>\n",
       "      <td>199</td>\n",
       "      <td>341</td>\n",
       "      <td>68</td>\n",
       "      <td>338</td>\n",
       "      <td>367</td>\n",
       "      <td>986</td>\n",
       "      <td>640</td>\n",
       "      <td>458</td>\n",
       "      <td>461</td>\n",
       "      <td>460</td>\n",
       "      <td>511</td>\n",
       "      <td>452</td>\n",
       "      <td>76</td>\n",
       "      <td>393</td>\n",
       "      <td>106</td>\n",
       "      <td>407</td>\n",
       "      <td>446</td>\n",
       "      <td>1357</td>\n",
       "      <td>118</td>\n",
       "      <td>393</td>\n",
       "      <td>249</td>\n",
       "      <td>1155</td>\n",
       "      <td>330</td>\n",
       "      <td>148</td>\n",
       "      <td>903</td>\n",
       "      <td>848</td>\n",
       "      <td>550</td>\n",
       "      <td>1708</td>\n",
       "      <td>1655</td>\n",
       "      <td>1346</td>\n",
       "      <td>1021</td>\n",
       "      <td>604</td>\n",
       "      <td>180</td>\n",
       "      <td>803</td>\n",
       "      <td>445</td>\n",
       "      <td>127</td>\n",
       "      <td>847</td>\n",
       "      <td>1625</td>\n",
       "      <td>461</td>\n",
       "      <td>315</td>\n",
       "      <td>857</td>\n",
       "      <td>205</td>\n",
       "      <td>399</td>\n",
       "      <td>968</td>\n",
       "      <td>794</td>\n",
       "      <td>176</td>\n",
       "      <td>793</td>\n",
       "      <td>Male</td>\n",
       "      <td>12-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>88M</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10093.000</td>\n",
       "      <td>250</td>\n",
       "      <td>1585</td>\n",
       "      <td>372</td>\n",
       "      <td>247</td>\n",
       "      <td>1478</td>\n",
       "      <td>267</td>\n",
       "      <td>224</td>\n",
       "      <td>435</td>\n",
       "      <td>356</td>\n",
       "      <td>263</td>\n",
       "      <td>524</td>\n",
       "      <td>80</td>\n",
       "      <td>340</td>\n",
       "      <td>310</td>\n",
       "      <td>138</td>\n",
       "      <td>1029</td>\n",
       "      <td>275</td>\n",
       "      <td>1080</td>\n",
       "      <td>706</td>\n",
       "      <td>567</td>\n",
       "      <td>425</td>\n",
       "      <td>1684</td>\n",
       "      <td>304</td>\n",
       "      <td>1048</td>\n",
       "      <td>232</td>\n",
       "      <td>1452</td>\n",
       "      <td>1014</td>\n",
       "      <td>682</td>\n",
       "      <td>382</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>814</td>\n",
       "      <td>111</td>\n",
       "      <td>305</td>\n",
       "      <td>399</td>\n",
       "      <td>324</td>\n",
       "      <td>605</td>\n",
       "      <td>550</td>\n",
       "      <td>1279</td>\n",
       "      <td>94</td>\n",
       "      <td>222</td>\n",
       "      <td>218</td>\n",
       "      <td>153</td>\n",
       "      <td>566</td>\n",
       "      <td>197</td>\n",
       "      <td>374</td>\n",
       "      <td>69</td>\n",
       "      <td>332</td>\n",
       "      <td>372</td>\n",
       "      <td>1251</td>\n",
       "      <td>675</td>\n",
       "      <td>481</td>\n",
       "      <td>505</td>\n",
       "      <td>612</td>\n",
       "      <td>666</td>\n",
       "      <td>585</td>\n",
       "      <td>85</td>\n",
       "      <td>458</td>\n",
       "      <td>135</td>\n",
       "      <td>398</td>\n",
       "      <td>430</td>\n",
       "      <td>1572</td>\n",
       "      <td>132</td>\n",
       "      <td>523</td>\n",
       "      <td>302</td>\n",
       "      <td>1231</td>\n",
       "      <td>400</td>\n",
       "      <td>180</td>\n",
       "      <td>919</td>\n",
       "      <td>995</td>\n",
       "      <td>641</td>\n",
       "      <td>2035</td>\n",
       "      <td>1914</td>\n",
       "      <td>1596</td>\n",
       "      <td>1292</td>\n",
       "      <td>672</td>\n",
       "      <td>194</td>\n",
       "      <td>962</td>\n",
       "      <td>584</td>\n",
       "      <td>122</td>\n",
       "      <td>1090</td>\n",
       "      <td>1679</td>\n",
       "      <td>467</td>\n",
       "      <td>303</td>\n",
       "      <td>868</td>\n",
       "      <td>214</td>\n",
       "      <td>379</td>\n",
       "      <td>1245</td>\n",
       "      <td>946</td>\n",
       "      <td>188</td>\n",
       "      <td>954</td>\n",
       "      <td>Male</td>\n",
       "      <td>12-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>92G</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>Right hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectid  abdominalextensiondepthsitting  acromialheight  \\\n",
       "0  10027.000                             266            1467   \n",
       "1  10032.000                             233            1395   \n",
       "2  10033.000                             287            1430   \n",
       "3  10092.000                             234            1347   \n",
       "4  10093.000                             250            1585   \n",
       "\n",
       "   acromionradialelength  anklecircumference  axillaheight  \\\n",
       "0                    337                 222          1347   \n",
       "1                    326                 220          1293   \n",
       "2                    341                 230          1327   \n",
       "3                    310                 230          1239   \n",
       "4                    372                 247          1478   \n",
       "\n",
       "   balloffootcircumference  balloffootlength  biacromialbreadth  \\\n",
       "0                      253               202                401   \n",
       "1                      245               193                394   \n",
       "2                      256               196                427   \n",
       "3                      262               199                401   \n",
       "4                      267               224                435   \n",
       "\n",
       "   bicepscircumferenceflexed  bicristalbreadth  bideltoidbreadth  \\\n",
       "0                        369               274               493   \n",
       "1                        338               257               479   \n",
       "2                        408               261               544   \n",
       "3                        359               262               518   \n",
       "4                        356               263               524   \n",
       "\n",
       "   bimalleolarbreadth  bitragionchinarc  bitragionsubmandibulararc  \\\n",
       "0                  71               319                        291   \n",
       "1                  67               344                        320   \n",
       "2                  75               345                        330   \n",
       "3                  73               328                        309   \n",
       "4                  80               340                        310   \n",
       "\n",
       "   bizygomaticbreadth  buttockcircumference  buttockdepth  buttockheight  \\\n",
       "0                 142                   979           240            882   \n",
       "1                 135                   944           232            870   \n",
       "2                 135                  1054           258            901   \n",
       "3                 143                   991           242            821   \n",
       "4                 138                  1029           275           1080   \n",
       "\n",
       "   buttockkneelength  buttockpopliteallength  calfcircumference  \\\n",
       "0                619                     509                373   \n",
       "1                584                     468                357   \n",
       "2                623                     506                412   \n",
       "3                560                     437                395   \n",
       "4                706                     567                425   \n",
       "\n",
       "   cervicaleheight  chestbreadth  chestcircumference  chestdepth  chestheight  \\\n",
       "0             1535           291                1074         259         1292   \n",
       "1             1471           269                1021         253         1244   \n",
       "2             1501           288                1120         267         1288   \n",
       "3             1423           296                1114         262         1205   \n",
       "4             1684           304                1048         232         1452   \n",
       "\n",
       "   crotchheight  crotchlengthomphalion  crotchlengthposterioromphalion  \\\n",
       "0           877                    607                             351   \n",
       "1           851                    615                             376   \n",
       "2           854                    636                             359   \n",
       "3           769                    590                             341   \n",
       "4          1014                    682                             382   \n",
       "\n",
       "   earbreadth  earlength  earprotrusion  elbowrestheight  eyeheightsitting  \\\n",
       "0          36         71             19              247               802   \n",
       "1          33         62             18              232               781   \n",
       "2          40         61             23              237               810   \n",
       "3          39         66             25              272               794   \n",
       "4          32         56             19              188               814   \n",
       "\n",
       "   footbreadthhorizontal  footlength  forearmcenterofgriplength  \\\n",
       "0                    101         273                        349   \n",
       "1                     98         263                        348   \n",
       "2                    103         270                        355   \n",
       "3                    106         267                        352   \n",
       "4                    111         305                        399   \n",
       "\n",
       "   forearmcircumferenceflexed  forearmforearmbreadth  forearmhandlength  \\\n",
       "0                         299                    575                477   \n",
       "1                         289                    523                476   \n",
       "2                         357                    575                491   \n",
       "3                         318                    593                467   \n",
       "4                         324                    605                550   \n",
       "\n",
       "   functionalleglength  handbreadth  handcircumference  handlength  \\\n",
       "0                 1136           90                214         193   \n",
       "1                 1096           86                203         195   \n",
       "2                 1115           93                220         203   \n",
       "3                 1034           91                217         194   \n",
       "4                 1279           94                222         218   \n",
       "\n",
       "   headbreadth  headcircumference  headlength  heelanklecircumference  \\\n",
       "0          150                583         206                     326   \n",
       "1          146                568         201                     334   \n",
       "2          148                573         202                     356   \n",
       "3          158                576         199                     341   \n",
       "4          153                566         197                     374   \n",
       "\n",
       "   heelbreadth  hipbreadth  hipbreadthsitting  iliocristaleheight  \\\n",
       "0           70         332                366                1071   \n",
       "1           72         312                356                1046   \n",
       "2           70         349                393                1053   \n",
       "3           68         338                367                 986   \n",
       "4           69         332                372                1251   \n",
       "\n",
       "   interpupillarybreadth  interscyei  interscyeii  kneeheightmidpatella  \\\n",
       "0                    685         422          441                   502   \n",
       "1                    620         441          447                   490   \n",
       "2                    665         462          475                   496   \n",
       "3                    640         458          461                   460   \n",
       "4                    675         481          505                   612   \n",
       "\n",
       "   kneeheightsitting  lateralfemoralepicondyleheight  lateralmalleolusheight  \\\n",
       "0                560                             500                      77   \n",
       "1                540                             488                      73   \n",
       "2                556                             482                      72   \n",
       "3                511                             452                      76   \n",
       "4                666                             585                      85   \n",
       "\n",
       "   lowerthighcircumference  mentonsellionlength  neckcircumference  \\\n",
       "0                      391                  118                400   \n",
       "1                      371                  131                380   \n",
       "2                      409                  123                403   \n",
       "3                      393                  106                407   \n",
       "4                      458                  135                398   \n",
       "\n",
       "   neckcircumferencebase  overheadfingertipreachsitting  palmlength  \\\n",
       "0                    436                           1447         113   \n",
       "1                    420                           1380         118   \n",
       "2                    434                           1447         121   \n",
       "3                    446                           1357         118   \n",
       "4                    430                           1572         132   \n",
       "\n",
       "   poplitealheight  radialestylionlength  shouldercircumference  \\\n",
       "0              437                   273                   1151   \n",
       "1              417                   254                   1119   \n",
       "2              431                   268                   1276   \n",
       "3              393                   249                   1155   \n",
       "4              523                   302                   1231   \n",
       "\n",
       "   shoulderelbowlength  shoulderlength  sittingheight  sleevelengthspinewrist  \\\n",
       "0                  368             145            928                     883   \n",
       "1                  353             141            884                     868   \n",
       "2                  367             167            917                     910   \n",
       "3                  330             148            903                     848   \n",
       "4                  400             180            919                     995   \n",
       "\n",
       "   sleeveoutseam  span  stature  suprasternaleheight  tenthribheight  \\\n",
       "0            600  1782     1776                 1449            1092   \n",
       "1            564  1745     1702                 1387            1076   \n",
       "2            604  1867     1735                 1438            1105   \n",
       "3            550  1708     1655                 1346            1021   \n",
       "4            641  2035     1914                 1596            1292   \n",
       "\n",
       "   thighcircumference  thighclearance  thumbtipreach  tibialheight  \\\n",
       "0                 610             164            786           491   \n",
       "1                 572             169            822           476   \n",
       "2                 685             198            807           477   \n",
       "3                 604             180            803           445   \n",
       "4                 672             194            962           584   \n",
       "\n",
       "   tragiontopofhead  trochanterionheight  verticaltrunkcircumferenceusa  \\\n",
       "0               140                  919                           1700   \n",
       "1               120                  918                           1627   \n",
       "2               125                  918                           1678   \n",
       "3               127                  847                           1625   \n",
       "4               122                 1090                           1679   \n",
       "\n",
       "   waistbacklength  waistbreadth  waistcircumference  waistdepth  \\\n",
       "0              501           329                 933         240   \n",
       "1              432           316                 870         225   \n",
       "2              472           329                 964         255   \n",
       "3              461           315                 857         205   \n",
       "4              467           303                 868         214   \n",
       "\n",
       "   waistfrontlengthsitting  waistheightomphalion  weightkg  \\\n",
       "0                      440                  1054       815   \n",
       "1                      371                  1054       726   \n",
       "2                      411                  1041       929   \n",
       "3                      399                   968       794   \n",
       "4                      379                  1245       946   \n",
       "\n",
       "   wristcircumference  wristheight Gender       Date Installation  \\\n",
       "0                 175          853   Male   4-Oct-10    Fort Hood   \n",
       "1                 167          815   Male   4-Oct-10    Fort Hood   \n",
       "2                 180          831   Male   4-Oct-10    Fort Hood   \n",
       "3                 176          793   Male  12-Oct-10    Fort Hood   \n",
       "4                 188          954   Male  12-Oct-10    Fort Hood   \n",
       "\n",
       "      Component                  Branch PrimaryMOS SubjectsBirthLocation  \\\n",
       "0  Regular Army             Combat Arms        19D          North Dakota   \n",
       "1  Regular Army          Combat Support        68W              New York   \n",
       "2  Regular Army          Combat Support        68W              New York   \n",
       "3  Regular Army  Combat Service Support        88M             Wisconsin   \n",
       "4  Regular Army  Combat Service Support        92G        North Carolina   \n",
       "\n",
       "   SubjectNumericRace Ethnicity  DODRace  Age  Heightin  Weightlbs  \\\n",
       "0                   1       NaN        1   41        71        180   \n",
       "1                   1       NaN        1   35        68        160   \n",
       "2                   2       NaN        2   42        68        205   \n",
       "3                   1       NaN        1   31        66        175   \n",
       "4                   2       NaN        2   21        77        213   \n",
       "\n",
       "  WritingPreference  SubjectId  \n",
       "0        Right hand        NaN  \n",
       "1         Left hand        NaN  \n",
       "2         Left hand        NaN  \n",
       "3        Right hand        NaN  \n",
       "4        Right hand        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "TMjCTEG51b67"
   },
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "hidden": true,
    "id": "SnlGRPWbrNAj",
    "outputId": "29ed8227-1450-4213-e9d1-a2953167d415",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6068 entries, 0 to 6067\n",
      "Data columns (total 109 columns):\n",
      " #    Column                          Dtype  \n",
      "---   ------                          -----  \n",
      " 0    subjectid                       float64\n",
      " 1    abdominalextensiondepthsitting  int64  \n",
      " 2    acromialheight                  int64  \n",
      " 3    acromionradialelength           int64  \n",
      " 4    anklecircumference              int64  \n",
      " 5    axillaheight                    int64  \n",
      " 6    balloffootcircumference         int64  \n",
      " 7    balloffootlength                int64  \n",
      " 8    biacromialbreadth               int64  \n",
      " 9    bicepscircumferenceflexed       int64  \n",
      " 10   bicristalbreadth                int64  \n",
      " 11   bideltoidbreadth                int64  \n",
      " 12   bimalleolarbreadth              int64  \n",
      " 13   bitragionchinarc                int64  \n",
      " 14   bitragionsubmandibulararc       int64  \n",
      " 15   bizygomaticbreadth              int64  \n",
      " 16   buttockcircumference            int64  \n",
      " 17   buttockdepth                    int64  \n",
      " 18   buttockheight                   int64  \n",
      " 19   buttockkneelength               int64  \n",
      " 20   buttockpopliteallength          int64  \n",
      " 21   calfcircumference               int64  \n",
      " 22   cervicaleheight                 int64  \n",
      " 23   chestbreadth                    int64  \n",
      " 24   chestcircumference              int64  \n",
      " 25   chestdepth                      int64  \n",
      " 26   chestheight                     int64  \n",
      " 27   crotchheight                    int64  \n",
      " 28   crotchlengthomphalion           int64  \n",
      " 29   crotchlengthposterioromphalion  int64  \n",
      " 30   earbreadth                      int64  \n",
      " 31   earlength                       int64  \n",
      " 32   earprotrusion                   int64  \n",
      " 33   elbowrestheight                 int64  \n",
      " 34   eyeheightsitting                int64  \n",
      " 35   footbreadthhorizontal           int64  \n",
      " 36   footlength                      int64  \n",
      " 37   forearmcenterofgriplength       int64  \n",
      " 38   forearmcircumferenceflexed      int64  \n",
      " 39   forearmforearmbreadth           int64  \n",
      " 40   forearmhandlength               int64  \n",
      " 41   functionalleglength             int64  \n",
      " 42   handbreadth                     int64  \n",
      " 43   handcircumference               int64  \n",
      " 44   handlength                      int64  \n",
      " 45   headbreadth                     int64  \n",
      " 46   headcircumference               int64  \n",
      " 47   headlength                      int64  \n",
      " 48   heelanklecircumference          int64  \n",
      " 49   heelbreadth                     int64  \n",
      " 50   hipbreadth                      int64  \n",
      " 51   hipbreadthsitting               int64  \n",
      " 52   iliocristaleheight              int64  \n",
      " 53   interpupillarybreadth           int64  \n",
      " 54   interscyei                      int64  \n",
      " 55   interscyeii                     int64  \n",
      " 56   kneeheightmidpatella            int64  \n",
      " 57   kneeheightsitting               int64  \n",
      " 58   lateralfemoralepicondyleheight  int64  \n",
      " 59   lateralmalleolusheight          int64  \n",
      " 60   lowerthighcircumference         int64  \n",
      " 61   mentonsellionlength             int64  \n",
      " 62   neckcircumference               int64  \n",
      " 63   neckcircumferencebase           int64  \n",
      " 64   overheadfingertipreachsitting   int64  \n",
      " 65   palmlength                      int64  \n",
      " 66   poplitealheight                 int64  \n",
      " 67   radialestylionlength            int64  \n",
      " 68   shouldercircumference           int64  \n",
      " 69   shoulderelbowlength             int64  \n",
      " 70   shoulderlength                  int64  \n",
      " 71   sittingheight                   int64  \n",
      " 72   sleevelengthspinewrist          int64  \n",
      " 73   sleeveoutseam                   int64  \n",
      " 74   span                            int64  \n",
      " 75   stature                         int64  \n",
      " 76   suprasternaleheight             int64  \n",
      " 77   tenthribheight                  int64  \n",
      " 78   thighcircumference              int64  \n",
      " 79   thighclearance                  int64  \n",
      " 80   thumbtipreach                   int64  \n",
      " 81   tibialheight                    int64  \n",
      " 82   tragiontopofhead                int64  \n",
      " 83   trochanterionheight             int64  \n",
      " 84   verticaltrunkcircumferenceusa   int64  \n",
      " 85   waistbacklength                 int64  \n",
      " 86   waistbreadth                    int64  \n",
      " 87   waistcircumference              int64  \n",
      " 88   waistdepth                      int64  \n",
      " 89   waistfrontlengthsitting         int64  \n",
      " 90   waistheightomphalion            int64  \n",
      " 91   weightkg                        int64  \n",
      " 92   wristcircumference              int64  \n",
      " 93   wristheight                     int64  \n",
      " 94   Gender                          object \n",
      " 95   Date                            object \n",
      " 96   Installation                    object \n",
      " 97   Component                       object \n",
      " 98   Branch                          object \n",
      " 99   PrimaryMOS                      object \n",
      " 100  SubjectsBirthLocation           object \n",
      " 101  SubjectNumericRace              int64  \n",
      " 102  Ethnicity                       object \n",
      " 103  DODRace                         int64  \n",
      " 104  Age                             int64  \n",
      " 105  Heightin                        int64  \n",
      " 106  Weightlbs                       int64  \n",
      " 107  WritingPreference               object \n",
      " 108  SubjectId                       float64\n",
      "dtypes: float64(2), int64(98), object(9)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectid</th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>bideltoidbreadth</th>\n",
       "      <th>bimalleolarbreadth</th>\n",
       "      <th>bitragionchinarc</th>\n",
       "      <th>bitragionsubmandibulararc</th>\n",
       "      <th>bizygomaticbreadth</th>\n",
       "      <th>buttockcircumference</th>\n",
       "      <th>buttockdepth</th>\n",
       "      <th>buttockheight</th>\n",
       "      <th>buttockkneelength</th>\n",
       "      <th>buttockpopliteallength</th>\n",
       "      <th>calfcircumference</th>\n",
       "      <th>cervicaleheight</th>\n",
       "      <th>chestbreadth</th>\n",
       "      <th>chestcircumference</th>\n",
       "      <th>chestdepth</th>\n",
       "      <th>chestheight</th>\n",
       "      <th>crotchheight</th>\n",
       "      <th>crotchlengthomphalion</th>\n",
       "      <th>crotchlengthposterioromphalion</th>\n",
       "      <th>earbreadth</th>\n",
       "      <th>earlength</th>\n",
       "      <th>earprotrusion</th>\n",
       "      <th>elbowrestheight</th>\n",
       "      <th>eyeheightsitting</th>\n",
       "      <th>footbreadthhorizontal</th>\n",
       "      <th>footlength</th>\n",
       "      <th>forearmcenterofgriplength</th>\n",
       "      <th>forearmcircumferenceflexed</th>\n",
       "      <th>forearmforearmbreadth</th>\n",
       "      <th>forearmhandlength</th>\n",
       "      <th>functionalleglength</th>\n",
       "      <th>handbreadth</th>\n",
       "      <th>handcircumference</th>\n",
       "      <th>handlength</th>\n",
       "      <th>headbreadth</th>\n",
       "      <th>headcircumference</th>\n",
       "      <th>headlength</th>\n",
       "      <th>heelanklecircumference</th>\n",
       "      <th>heelbreadth</th>\n",
       "      <th>hipbreadth</th>\n",
       "      <th>hipbreadthsitting</th>\n",
       "      <th>iliocristaleheight</th>\n",
       "      <th>interpupillarybreadth</th>\n",
       "      <th>interscyei</th>\n",
       "      <th>interscyeii</th>\n",
       "      <th>kneeheightmidpatella</th>\n",
       "      <th>kneeheightsitting</th>\n",
       "      <th>lateralfemoralepicondyleheight</th>\n",
       "      <th>lateralmalleolusheight</th>\n",
       "      <th>lowerthighcircumference</th>\n",
       "      <th>mentonsellionlength</th>\n",
       "      <th>neckcircumference</th>\n",
       "      <th>neckcircumferencebase</th>\n",
       "      <th>overheadfingertipreachsitting</th>\n",
       "      <th>palmlength</th>\n",
       "      <th>poplitealheight</th>\n",
       "      <th>radialestylionlength</th>\n",
       "      <th>shouldercircumference</th>\n",
       "      <th>shoulderelbowlength</th>\n",
       "      <th>shoulderlength</th>\n",
       "      <th>sittingheight</th>\n",
       "      <th>sleevelengthspinewrist</th>\n",
       "      <th>sleeveoutseam</th>\n",
       "      <th>span</th>\n",
       "      <th>stature</th>\n",
       "      <th>suprasternaleheight</th>\n",
       "      <th>tenthribheight</th>\n",
       "      <th>thighcircumference</th>\n",
       "      <th>thighclearance</th>\n",
       "      <th>thumbtipreach</th>\n",
       "      <th>tibialheight</th>\n",
       "      <th>tragiontopofhead</th>\n",
       "      <th>trochanterionheight</th>\n",
       "      <th>verticaltrunkcircumferenceusa</th>\n",
       "      <th>waistbacklength</th>\n",
       "      <th>waistbreadth</th>\n",
       "      <th>waistcircumference</th>\n",
       "      <th>waistdepth</th>\n",
       "      <th>waistfrontlengthsitting</th>\n",
       "      <th>waistheightomphalion</th>\n",
       "      <th>weightkg</th>\n",
       "      <th>wristcircumference</th>\n",
       "      <th>wristheight</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Component</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "      <th>SubjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10027.000</td>\n",
       "      <td>266</td>\n",
       "      <td>1467</td>\n",
       "      <td>337</td>\n",
       "      <td>222</td>\n",
       "      <td>1347</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>274</td>\n",
       "      <td>493</td>\n",
       "      <td>71</td>\n",
       "      <td>319</td>\n",
       "      <td>291</td>\n",
       "      <td>142</td>\n",
       "      <td>979</td>\n",
       "      <td>240</td>\n",
       "      <td>882</td>\n",
       "      <td>619</td>\n",
       "      <td>509</td>\n",
       "      <td>373</td>\n",
       "      <td>1535</td>\n",
       "      <td>291</td>\n",
       "      <td>1074</td>\n",
       "      <td>259</td>\n",
       "      <td>1292</td>\n",
       "      <td>877</td>\n",
       "      <td>607</td>\n",
       "      <td>351</td>\n",
       "      <td>36</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>247</td>\n",
       "      <td>802</td>\n",
       "      <td>101</td>\n",
       "      <td>273</td>\n",
       "      <td>349</td>\n",
       "      <td>299</td>\n",
       "      <td>575</td>\n",
       "      <td>477</td>\n",
       "      <td>1136</td>\n",
       "      <td>90</td>\n",
       "      <td>214</td>\n",
       "      <td>193</td>\n",
       "      <td>150</td>\n",
       "      <td>583</td>\n",
       "      <td>206</td>\n",
       "      <td>326</td>\n",
       "      <td>70</td>\n",
       "      <td>332</td>\n",
       "      <td>366</td>\n",
       "      <td>1071</td>\n",
       "      <td>685</td>\n",
       "      <td>422</td>\n",
       "      <td>441</td>\n",
       "      <td>502</td>\n",
       "      <td>560</td>\n",
       "      <td>500</td>\n",
       "      <td>77</td>\n",
       "      <td>391</td>\n",
       "      <td>118</td>\n",
       "      <td>400</td>\n",
       "      <td>436</td>\n",
       "      <td>1447</td>\n",
       "      <td>113</td>\n",
       "      <td>437</td>\n",
       "      <td>273</td>\n",
       "      <td>1151</td>\n",
       "      <td>368</td>\n",
       "      <td>145</td>\n",
       "      <td>928</td>\n",
       "      <td>883</td>\n",
       "      <td>600</td>\n",
       "      <td>1782</td>\n",
       "      <td>1776</td>\n",
       "      <td>1449</td>\n",
       "      <td>1092</td>\n",
       "      <td>610</td>\n",
       "      <td>164</td>\n",
       "      <td>786</td>\n",
       "      <td>491</td>\n",
       "      <td>140</td>\n",
       "      <td>919</td>\n",
       "      <td>1700</td>\n",
       "      <td>501</td>\n",
       "      <td>329</td>\n",
       "      <td>933</td>\n",
       "      <td>240</td>\n",
       "      <td>440</td>\n",
       "      <td>1054</td>\n",
       "      <td>815</td>\n",
       "      <td>175</td>\n",
       "      <td>853</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>19D</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>180</td>\n",
       "      <td>Right hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10032.000</td>\n",
       "      <td>233</td>\n",
       "      <td>1395</td>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>1293</td>\n",
       "      <td>245</td>\n",
       "      <td>193</td>\n",
       "      <td>394</td>\n",
       "      <td>338</td>\n",
       "      <td>257</td>\n",
       "      <td>479</td>\n",
       "      <td>67</td>\n",
       "      <td>344</td>\n",
       "      <td>320</td>\n",
       "      <td>135</td>\n",
       "      <td>944</td>\n",
       "      <td>232</td>\n",
       "      <td>870</td>\n",
       "      <td>584</td>\n",
       "      <td>468</td>\n",
       "      <td>357</td>\n",
       "      <td>1471</td>\n",
       "      <td>269</td>\n",
       "      <td>1021</td>\n",
       "      <td>253</td>\n",
       "      <td>1244</td>\n",
       "      <td>851</td>\n",
       "      <td>615</td>\n",
       "      <td>376</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>781</td>\n",
       "      <td>98</td>\n",
       "      <td>263</td>\n",
       "      <td>348</td>\n",
       "      <td>289</td>\n",
       "      <td>523</td>\n",
       "      <td>476</td>\n",
       "      <td>1096</td>\n",
       "      <td>86</td>\n",
       "      <td>203</td>\n",
       "      <td>195</td>\n",
       "      <td>146</td>\n",
       "      <td>568</td>\n",
       "      <td>201</td>\n",
       "      <td>334</td>\n",
       "      <td>72</td>\n",
       "      <td>312</td>\n",
       "      <td>356</td>\n",
       "      <td>1046</td>\n",
       "      <td>620</td>\n",
       "      <td>441</td>\n",
       "      <td>447</td>\n",
       "      <td>490</td>\n",
       "      <td>540</td>\n",
       "      <td>488</td>\n",
       "      <td>73</td>\n",
       "      <td>371</td>\n",
       "      <td>131</td>\n",
       "      <td>380</td>\n",
       "      <td>420</td>\n",
       "      <td>1380</td>\n",
       "      <td>118</td>\n",
       "      <td>417</td>\n",
       "      <td>254</td>\n",
       "      <td>1119</td>\n",
       "      <td>353</td>\n",
       "      <td>141</td>\n",
       "      <td>884</td>\n",
       "      <td>868</td>\n",
       "      <td>564</td>\n",
       "      <td>1745</td>\n",
       "      <td>1702</td>\n",
       "      <td>1387</td>\n",
       "      <td>1076</td>\n",
       "      <td>572</td>\n",
       "      <td>169</td>\n",
       "      <td>822</td>\n",
       "      <td>476</td>\n",
       "      <td>120</td>\n",
       "      <td>918</td>\n",
       "      <td>1627</td>\n",
       "      <td>432</td>\n",
       "      <td>316</td>\n",
       "      <td>870</td>\n",
       "      <td>225</td>\n",
       "      <td>371</td>\n",
       "      <td>1054</td>\n",
       "      <td>726</td>\n",
       "      <td>167</td>\n",
       "      <td>815</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>160</td>\n",
       "      <td>Left hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10033.000</td>\n",
       "      <td>287</td>\n",
       "      <td>1430</td>\n",
       "      <td>341</td>\n",
       "      <td>230</td>\n",
       "      <td>1327</td>\n",
       "      <td>256</td>\n",
       "      <td>196</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>261</td>\n",
       "      <td>544</td>\n",
       "      <td>75</td>\n",
       "      <td>345</td>\n",
       "      <td>330</td>\n",
       "      <td>135</td>\n",
       "      <td>1054</td>\n",
       "      <td>258</td>\n",
       "      <td>901</td>\n",
       "      <td>623</td>\n",
       "      <td>506</td>\n",
       "      <td>412</td>\n",
       "      <td>1501</td>\n",
       "      <td>288</td>\n",
       "      <td>1120</td>\n",
       "      <td>267</td>\n",
       "      <td>1288</td>\n",
       "      <td>854</td>\n",
       "      <td>636</td>\n",
       "      <td>359</td>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>237</td>\n",
       "      <td>810</td>\n",
       "      <td>103</td>\n",
       "      <td>270</td>\n",
       "      <td>355</td>\n",
       "      <td>357</td>\n",
       "      <td>575</td>\n",
       "      <td>491</td>\n",
       "      <td>1115</td>\n",
       "      <td>93</td>\n",
       "      <td>220</td>\n",
       "      <td>203</td>\n",
       "      <td>148</td>\n",
       "      <td>573</td>\n",
       "      <td>202</td>\n",
       "      <td>356</td>\n",
       "      <td>70</td>\n",
       "      <td>349</td>\n",
       "      <td>393</td>\n",
       "      <td>1053</td>\n",
       "      <td>665</td>\n",
       "      <td>462</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>556</td>\n",
       "      <td>482</td>\n",
       "      <td>72</td>\n",
       "      <td>409</td>\n",
       "      <td>123</td>\n",
       "      <td>403</td>\n",
       "      <td>434</td>\n",
       "      <td>1447</td>\n",
       "      <td>121</td>\n",
       "      <td>431</td>\n",
       "      <td>268</td>\n",
       "      <td>1276</td>\n",
       "      <td>367</td>\n",
       "      <td>167</td>\n",
       "      <td>917</td>\n",
       "      <td>910</td>\n",
       "      <td>604</td>\n",
       "      <td>1867</td>\n",
       "      <td>1735</td>\n",
       "      <td>1438</td>\n",
       "      <td>1105</td>\n",
       "      <td>685</td>\n",
       "      <td>198</td>\n",
       "      <td>807</td>\n",
       "      <td>477</td>\n",
       "      <td>125</td>\n",
       "      <td>918</td>\n",
       "      <td>1678</td>\n",
       "      <td>472</td>\n",
       "      <td>329</td>\n",
       "      <td>964</td>\n",
       "      <td>255</td>\n",
       "      <td>411</td>\n",
       "      <td>1041</td>\n",
       "      <td>929</td>\n",
       "      <td>180</td>\n",
       "      <td>831</td>\n",
       "      <td>Male</td>\n",
       "      <td>4-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>205</td>\n",
       "      <td>Left hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10092.000</td>\n",
       "      <td>234</td>\n",
       "      <td>1347</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>1239</td>\n",
       "      <td>262</td>\n",
       "      <td>199</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>262</td>\n",
       "      <td>518</td>\n",
       "      <td>73</td>\n",
       "      <td>328</td>\n",
       "      <td>309</td>\n",
       "      <td>143</td>\n",
       "      <td>991</td>\n",
       "      <td>242</td>\n",
       "      <td>821</td>\n",
       "      <td>560</td>\n",
       "      <td>437</td>\n",
       "      <td>395</td>\n",
       "      <td>1423</td>\n",
       "      <td>296</td>\n",
       "      <td>1114</td>\n",
       "      <td>262</td>\n",
       "      <td>1205</td>\n",
       "      <td>769</td>\n",
       "      <td>590</td>\n",
       "      <td>341</td>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>272</td>\n",
       "      <td>794</td>\n",
       "      <td>106</td>\n",
       "      <td>267</td>\n",
       "      <td>352</td>\n",
       "      <td>318</td>\n",
       "      <td>593</td>\n",
       "      <td>467</td>\n",
       "      <td>1034</td>\n",
       "      <td>91</td>\n",
       "      <td>217</td>\n",
       "      <td>194</td>\n",
       "      <td>158</td>\n",
       "      <td>576</td>\n",
       "      <td>199</td>\n",
       "      <td>341</td>\n",
       "      <td>68</td>\n",
       "      <td>338</td>\n",
       "      <td>367</td>\n",
       "      <td>986</td>\n",
       "      <td>640</td>\n",
       "      <td>458</td>\n",
       "      <td>461</td>\n",
       "      <td>460</td>\n",
       "      <td>511</td>\n",
       "      <td>452</td>\n",
       "      <td>76</td>\n",
       "      <td>393</td>\n",
       "      <td>106</td>\n",
       "      <td>407</td>\n",
       "      <td>446</td>\n",
       "      <td>1357</td>\n",
       "      <td>118</td>\n",
       "      <td>393</td>\n",
       "      <td>249</td>\n",
       "      <td>1155</td>\n",
       "      <td>330</td>\n",
       "      <td>148</td>\n",
       "      <td>903</td>\n",
       "      <td>848</td>\n",
       "      <td>550</td>\n",
       "      <td>1708</td>\n",
       "      <td>1655</td>\n",
       "      <td>1346</td>\n",
       "      <td>1021</td>\n",
       "      <td>604</td>\n",
       "      <td>180</td>\n",
       "      <td>803</td>\n",
       "      <td>445</td>\n",
       "      <td>127</td>\n",
       "      <td>847</td>\n",
       "      <td>1625</td>\n",
       "      <td>461</td>\n",
       "      <td>315</td>\n",
       "      <td>857</td>\n",
       "      <td>205</td>\n",
       "      <td>399</td>\n",
       "      <td>968</td>\n",
       "      <td>794</td>\n",
       "      <td>176</td>\n",
       "      <td>793</td>\n",
       "      <td>Male</td>\n",
       "      <td>12-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>88M</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10093.000</td>\n",
       "      <td>250</td>\n",
       "      <td>1585</td>\n",
       "      <td>372</td>\n",
       "      <td>247</td>\n",
       "      <td>1478</td>\n",
       "      <td>267</td>\n",
       "      <td>224</td>\n",
       "      <td>435</td>\n",
       "      <td>356</td>\n",
       "      <td>263</td>\n",
       "      <td>524</td>\n",
       "      <td>80</td>\n",
       "      <td>340</td>\n",
       "      <td>310</td>\n",
       "      <td>138</td>\n",
       "      <td>1029</td>\n",
       "      <td>275</td>\n",
       "      <td>1080</td>\n",
       "      <td>706</td>\n",
       "      <td>567</td>\n",
       "      <td>425</td>\n",
       "      <td>1684</td>\n",
       "      <td>304</td>\n",
       "      <td>1048</td>\n",
       "      <td>232</td>\n",
       "      <td>1452</td>\n",
       "      <td>1014</td>\n",
       "      <td>682</td>\n",
       "      <td>382</td>\n",
       "      <td>32</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>814</td>\n",
       "      <td>111</td>\n",
       "      <td>305</td>\n",
       "      <td>399</td>\n",
       "      <td>324</td>\n",
       "      <td>605</td>\n",
       "      <td>550</td>\n",
       "      <td>1279</td>\n",
       "      <td>94</td>\n",
       "      <td>222</td>\n",
       "      <td>218</td>\n",
       "      <td>153</td>\n",
       "      <td>566</td>\n",
       "      <td>197</td>\n",
       "      <td>374</td>\n",
       "      <td>69</td>\n",
       "      <td>332</td>\n",
       "      <td>372</td>\n",
       "      <td>1251</td>\n",
       "      <td>675</td>\n",
       "      <td>481</td>\n",
       "      <td>505</td>\n",
       "      <td>612</td>\n",
       "      <td>666</td>\n",
       "      <td>585</td>\n",
       "      <td>85</td>\n",
       "      <td>458</td>\n",
       "      <td>135</td>\n",
       "      <td>398</td>\n",
       "      <td>430</td>\n",
       "      <td>1572</td>\n",
       "      <td>132</td>\n",
       "      <td>523</td>\n",
       "      <td>302</td>\n",
       "      <td>1231</td>\n",
       "      <td>400</td>\n",
       "      <td>180</td>\n",
       "      <td>919</td>\n",
       "      <td>995</td>\n",
       "      <td>641</td>\n",
       "      <td>2035</td>\n",
       "      <td>1914</td>\n",
       "      <td>1596</td>\n",
       "      <td>1292</td>\n",
       "      <td>672</td>\n",
       "      <td>194</td>\n",
       "      <td>962</td>\n",
       "      <td>584</td>\n",
       "      <td>122</td>\n",
       "      <td>1090</td>\n",
       "      <td>1679</td>\n",
       "      <td>467</td>\n",
       "      <td>303</td>\n",
       "      <td>868</td>\n",
       "      <td>214</td>\n",
       "      <td>379</td>\n",
       "      <td>1245</td>\n",
       "      <td>946</td>\n",
       "      <td>188</td>\n",
       "      <td>954</td>\n",
       "      <td>Male</td>\n",
       "      <td>12-Oct-10</td>\n",
       "      <td>Fort Hood</td>\n",
       "      <td>Regular Army</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>92G</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>Right hand</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subjectid  abdominalextensiondepthsitting  acromialheight  \\\n",
       "0  10027.000                             266            1467   \n",
       "1  10032.000                             233            1395   \n",
       "2  10033.000                             287            1430   \n",
       "3  10092.000                             234            1347   \n",
       "4  10093.000                             250            1585   \n",
       "\n",
       "   acromionradialelength  anklecircumference  axillaheight  \\\n",
       "0                    337                 222          1347   \n",
       "1                    326                 220          1293   \n",
       "2                    341                 230          1327   \n",
       "3                    310                 230          1239   \n",
       "4                    372                 247          1478   \n",
       "\n",
       "   balloffootcircumference  balloffootlength  biacromialbreadth  \\\n",
       "0                      253               202                401   \n",
       "1                      245               193                394   \n",
       "2                      256               196                427   \n",
       "3                      262               199                401   \n",
       "4                      267               224                435   \n",
       "\n",
       "   bicepscircumferenceflexed  bicristalbreadth  bideltoidbreadth  \\\n",
       "0                        369               274               493   \n",
       "1                        338               257               479   \n",
       "2                        408               261               544   \n",
       "3                        359               262               518   \n",
       "4                        356               263               524   \n",
       "\n",
       "   bimalleolarbreadth  bitragionchinarc  bitragionsubmandibulararc  \\\n",
       "0                  71               319                        291   \n",
       "1                  67               344                        320   \n",
       "2                  75               345                        330   \n",
       "3                  73               328                        309   \n",
       "4                  80               340                        310   \n",
       "\n",
       "   bizygomaticbreadth  buttockcircumference  buttockdepth  buttockheight  \\\n",
       "0                 142                   979           240            882   \n",
       "1                 135                   944           232            870   \n",
       "2                 135                  1054           258            901   \n",
       "3                 143                   991           242            821   \n",
       "4                 138                  1029           275           1080   \n",
       "\n",
       "   buttockkneelength  buttockpopliteallength  calfcircumference  \\\n",
       "0                619                     509                373   \n",
       "1                584                     468                357   \n",
       "2                623                     506                412   \n",
       "3                560                     437                395   \n",
       "4                706                     567                425   \n",
       "\n",
       "   cervicaleheight  chestbreadth  chestcircumference  chestdepth  chestheight  \\\n",
       "0             1535           291                1074         259         1292   \n",
       "1             1471           269                1021         253         1244   \n",
       "2             1501           288                1120         267         1288   \n",
       "3             1423           296                1114         262         1205   \n",
       "4             1684           304                1048         232         1452   \n",
       "\n",
       "   crotchheight  crotchlengthomphalion  crotchlengthposterioromphalion  \\\n",
       "0           877                    607                             351   \n",
       "1           851                    615                             376   \n",
       "2           854                    636                             359   \n",
       "3           769                    590                             341   \n",
       "4          1014                    682                             382   \n",
       "\n",
       "   earbreadth  earlength  earprotrusion  elbowrestheight  eyeheightsitting  \\\n",
       "0          36         71             19              247               802   \n",
       "1          33         62             18              232               781   \n",
       "2          40         61             23              237               810   \n",
       "3          39         66             25              272               794   \n",
       "4          32         56             19              188               814   \n",
       "\n",
       "   footbreadthhorizontal  footlength  forearmcenterofgriplength  \\\n",
       "0                    101         273                        349   \n",
       "1                     98         263                        348   \n",
       "2                    103         270                        355   \n",
       "3                    106         267                        352   \n",
       "4                    111         305                        399   \n",
       "\n",
       "   forearmcircumferenceflexed  forearmforearmbreadth  forearmhandlength  \\\n",
       "0                         299                    575                477   \n",
       "1                         289                    523                476   \n",
       "2                         357                    575                491   \n",
       "3                         318                    593                467   \n",
       "4                         324                    605                550   \n",
       "\n",
       "   functionalleglength  handbreadth  handcircumference  handlength  \\\n",
       "0                 1136           90                214         193   \n",
       "1                 1096           86                203         195   \n",
       "2                 1115           93                220         203   \n",
       "3                 1034           91                217         194   \n",
       "4                 1279           94                222         218   \n",
       "\n",
       "   headbreadth  headcircumference  headlength  heelanklecircumference  \\\n",
       "0          150                583         206                     326   \n",
       "1          146                568         201                     334   \n",
       "2          148                573         202                     356   \n",
       "3          158                576         199                     341   \n",
       "4          153                566         197                     374   \n",
       "\n",
       "   heelbreadth  hipbreadth  hipbreadthsitting  iliocristaleheight  \\\n",
       "0           70         332                366                1071   \n",
       "1           72         312                356                1046   \n",
       "2           70         349                393                1053   \n",
       "3           68         338                367                 986   \n",
       "4           69         332                372                1251   \n",
       "\n",
       "   interpupillarybreadth  interscyei  interscyeii  kneeheightmidpatella  \\\n",
       "0                    685         422          441                   502   \n",
       "1                    620         441          447                   490   \n",
       "2                    665         462          475                   496   \n",
       "3                    640         458          461                   460   \n",
       "4                    675         481          505                   612   \n",
       "\n",
       "   kneeheightsitting  lateralfemoralepicondyleheight  lateralmalleolusheight  \\\n",
       "0                560                             500                      77   \n",
       "1                540                             488                      73   \n",
       "2                556                             482                      72   \n",
       "3                511                             452                      76   \n",
       "4                666                             585                      85   \n",
       "\n",
       "   lowerthighcircumference  mentonsellionlength  neckcircumference  \\\n",
       "0                      391                  118                400   \n",
       "1                      371                  131                380   \n",
       "2                      409                  123                403   \n",
       "3                      393                  106                407   \n",
       "4                      458                  135                398   \n",
       "\n",
       "   neckcircumferencebase  overheadfingertipreachsitting  palmlength  \\\n",
       "0                    436                           1447         113   \n",
       "1                    420                           1380         118   \n",
       "2                    434                           1447         121   \n",
       "3                    446                           1357         118   \n",
       "4                    430                           1572         132   \n",
       "\n",
       "   poplitealheight  radialestylionlength  shouldercircumference  \\\n",
       "0              437                   273                   1151   \n",
       "1              417                   254                   1119   \n",
       "2              431                   268                   1276   \n",
       "3              393                   249                   1155   \n",
       "4              523                   302                   1231   \n",
       "\n",
       "   shoulderelbowlength  shoulderlength  sittingheight  sleevelengthspinewrist  \\\n",
       "0                  368             145            928                     883   \n",
       "1                  353             141            884                     868   \n",
       "2                  367             167            917                     910   \n",
       "3                  330             148            903                     848   \n",
       "4                  400             180            919                     995   \n",
       "\n",
       "   sleeveoutseam  span  stature  suprasternaleheight  tenthribheight  \\\n",
       "0            600  1782     1776                 1449            1092   \n",
       "1            564  1745     1702                 1387            1076   \n",
       "2            604  1867     1735                 1438            1105   \n",
       "3            550  1708     1655                 1346            1021   \n",
       "4            641  2035     1914                 1596            1292   \n",
       "\n",
       "   thighcircumference  thighclearance  thumbtipreach  tibialheight  \\\n",
       "0                 610             164            786           491   \n",
       "1                 572             169            822           476   \n",
       "2                 685             198            807           477   \n",
       "3                 604             180            803           445   \n",
       "4                 672             194            962           584   \n",
       "\n",
       "   tragiontopofhead  trochanterionheight  verticaltrunkcircumferenceusa  \\\n",
       "0               140                  919                           1700   \n",
       "1               120                  918                           1627   \n",
       "2               125                  918                           1678   \n",
       "3               127                  847                           1625   \n",
       "4               122                 1090                           1679   \n",
       "\n",
       "   waistbacklength  waistbreadth  waistcircumference  waistdepth  \\\n",
       "0              501           329                 933         240   \n",
       "1              432           316                 870         225   \n",
       "2              472           329                 964         255   \n",
       "3              461           315                 857         205   \n",
       "4              467           303                 868         214   \n",
       "\n",
       "   waistfrontlengthsitting  waistheightomphalion  weightkg  \\\n",
       "0                      440                  1054       815   \n",
       "1                      371                  1054       726   \n",
       "2                      411                  1041       929   \n",
       "3                      399                   968       794   \n",
       "4                      379                  1245       946   \n",
       "\n",
       "   wristcircumference  wristheight Gender       Date Installation  \\\n",
       "0                 175          853   Male   4-Oct-10    Fort Hood   \n",
       "1                 167          815   Male   4-Oct-10    Fort Hood   \n",
       "2                 180          831   Male   4-Oct-10    Fort Hood   \n",
       "3                 176          793   Male  12-Oct-10    Fort Hood   \n",
       "4                 188          954   Male  12-Oct-10    Fort Hood   \n",
       "\n",
       "      Component                  Branch PrimaryMOS SubjectsBirthLocation  \\\n",
       "0  Regular Army             Combat Arms        19D          North Dakota   \n",
       "1  Regular Army          Combat Support        68W              New York   \n",
       "2  Regular Army          Combat Support        68W              New York   \n",
       "3  Regular Army  Combat Service Support        88M             Wisconsin   \n",
       "4  Regular Army  Combat Service Support        92G        North Carolina   \n",
       "\n",
       "   SubjectNumericRace Ethnicity  DODRace  Age  Heightin  Weightlbs  \\\n",
       "0                   1       NaN        1   41        71        180   \n",
       "1                   1       NaN        1   35        68        160   \n",
       "2                   2       NaN        2   42        68        205   \n",
       "3                   1       NaN        1   31        66        175   \n",
       "4                   2       NaN        2   21        77        213   \n",
       "\n",
       "  WritingPreference  SubjectId  \n",
       "0        Right hand        NaN  \n",
       "1         Left hand        NaN  \n",
       "2         Left hand        NaN  \n",
       "3        Right hand        NaN  \n",
       "4        Right hand        NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['subjectid','SubjectId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity = 4647\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    if df[c].isnull().sum()>0:\n",
    "        print(f\"{c} = {df[c].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ethnicity'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More than half of the Ennicity data is missing. Therefore I drop it\n",
    "df.drop(['Ethnicity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3792\n",
       "2    1298\n",
       "3     679\n",
       "4     188\n",
       "6      59\n",
       "5      49\n",
       "8       3\n",
       "Name: DODRace, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DODRace'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='DODRace', ylabel='count'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['DODRace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the races that are less than 500 counts:\n",
    "race_counts = df['DODRace'].value_counts()\n",
    "to_keep = race_counts[race_counts > 500].index\n",
    "df = df[df['DODRace'].isin(to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 106)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3792\n",
       "2    1298\n",
       "3     679\n",
       "Name: DODRace, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DODRace'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing race indices :\n",
    "df[\"DODRace\"] = df.DODRace.map({\n",
    "    1: \"White\",\n",
    "    2: \"Black\",\n",
    "    3: \"Hispanic\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe race classification shoiuld based on anthropometric measurements\n",
    "# Therefore I'll dropp all demographic/administrative columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['abdominalextensiondepthsitting', 'acromialheight',\n",
       "       'acromionradialelength', 'anklecircumference', 'axillaheight',\n",
       "       'balloffootcircumference', 'balloffootlength', 'biacromialbreadth',\n",
       "       'bicepscircumferenceflexed', 'bicristalbreadth',\n",
       "       ...\n",
       "       'Component', 'Branch', 'PrimaryMOS', 'SubjectsBirthLocation',\n",
       "       'SubjectNumericRace', 'DODRace', 'Age', 'Heightin', 'Weightlbs',\n",
       "       'WritingPreference'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['SubjectsBirthLocation','SubjectNumericRace',\n",
    "              'Age', 'Heightin', 'Weightlbs', 'WritingPreference',\n",
    "              'Date', 'Installation', 'Component', 'Branch', 'PrimaryMOS'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_list, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 95)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"] = df.Gender.map({\"Male\":1,\"Female\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"]= df[\"Gender\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "CS5-GZy0sl4s"
   },
   "source": [
    "# DATA Preprocessing\n",
    "- In this step we divide our data to X(Features) and y(Target) then ,\n",
    "- To train and evaluation purposes we create train and test sets,\n",
    "- Lastly, scale our data if features not in same scale. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true,
    "id": "fr2wgpvk1b7B"
   },
   "outputs": [],
   "source": [
    "X = df.drop('DODRace',axis=1)\n",
    "y = df['DODRace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=43, \n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape :  (4038, 94)\n",
      "Train target shape   :  (4038,)\n",
      "Test features shape  :  (1731, 94)\n",
      "Test target shape    :  (1731,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features shape : \", X_train.shape)\n",
    "print(\"Train target shape   : \", y_train.shape)\n",
    "print(\"Test features shape  : \", X_test.shape)\n",
    "print(\"Test target shape    : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zfi_NOw0s2fM"
   },
   "source": [
    "# Modelling\n",
    "- Fit the model with train dataset\n",
    "- Get predict from vanilla model on both train and test sets to examine if there is over/underfitting   \n",
    "- Apply GridseachCV for both hyperparemeter tuning and sanity test of our model.\n",
    "- Use hyperparameters that you find from gridsearch and make final prediction and evaluate the result according to chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test_Set_Scores\",\"\\n----------------\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set_Scores\",\"\\n----------------\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "N1cviBuh1b7C"
   },
   "source": [
    "## 1. Logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "0rSJ5hxp1b7C"
   },
   "source": [
    "### Vanilla Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(class_weight='balanced',max_iter=10000,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000, random_state=43)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[344  36   9]\n",
      " [ 23 133  48]\n",
      " [ 24 185 929]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.88      0.88      0.88       389\n",
      "    Hispanic       0.38      0.65      0.48       204\n",
      "       White       0.94      0.82      0.87      1138\n",
      "\n",
      "    accuracy                           0.81      1731\n",
      "   macro avg       0.73      0.78      0.74      1731\n",
      "weighted avg       0.86      0.81      0.83      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 832   50   27]\n",
      " [  38  348   89]\n",
      " [  55  480 2119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.90      0.92      0.91       909\n",
      "    Hispanic       0.40      0.73      0.51       475\n",
      "       White       0.95      0.80      0.87      2654\n",
      "\n",
      "    accuracy                           0.82      4038\n",
      "   macro avg       0.75      0.82      0.76      4038\n",
      "weighted avg       0.87      0.82      0.83      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(log, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing metrics for model comparison\n",
    "y_pred = log.predict(X_test)\n",
    "log_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "log_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "lPelWxsU1b7C"
   },
   "source": [
    "### Logistic Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8158, 0.807, 0.8074, 0.8256, 0.8406] \n",
      "\n",
      " f1score : 0.8192857034851526, std : %1.26 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "\n",
    "f1score= make_scorer(f1_score, average=\"weighted\")\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced',\n",
    "                           max_iter=10000,\n",
    "                           random_state=43)\n",
    "\n",
    "scores = cross_val_score(model,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         cv=5,\n",
    "                         scoring=f1score,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "print([round(i, 4) for i in scores], \"\\n\")\n",
    "print(f\" f1score : {scores.mean()}, std : %{scores.std()*100:.2f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing Grid Search to get better 'Hispanic' scores\n",
    "\n",
    "f1_Hispanic =  make_scorer(f1_score, average=None, labels=[\"Hispanic\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                'class_weight': [\"balanced\", None],\n",
    "                'penalty': [\"l1\", \"l2\"],\n",
    "                'solver': ['saga', 'lbfgs'],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced',\n",
    "                           max_iter=10000,\n",
    "                           random_state=43)\n",
    "\n",
    "log_model_grid = GridSearchCV(model,\n",
    "                              param_grid,\n",
    "                              verbose=3,\n",
    "                              scoring=f1_Hispanic,\n",
    "                              refit=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "PNZyqeNY15nP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 2/5] END class_weight=balanced, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END class_weight=balanced, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END class_weight=balanced, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END class_weight=balanced, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END class_weight=balanced, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END class_weight=balanced, penalty=l2, solver=saga;, score=0.440 total time=   0.8s\n",
      "[CV 2/5] END class_weight=balanced, penalty=l2, solver=saga;, score=0.452 total time=   0.9s\n",
      "[CV 3/5] END class_weight=balanced, penalty=l2, solver=saga;, score=0.456 total time=   0.9s\n",
      "[CV 1/5] END class_weight=balanced, penalty=l2, solver=lbfgs;, score=0.440 total time=   0.5s\n",
      "[CV 4/5] END class_weight=balanced, penalty=l2, solver=saga;, score=0.515 total time=   0.8s\n",
      "[CV 5/5] END class_weight=balanced, penalty=l2, solver=saga;, score=0.520 total time=   0.8s\n",
      "[CV 2/5] END class_weight=balanced, penalty=l2, solver=lbfgs;, score=0.452 total time=   0.5s\n",
      "[CV 4/5] END class_weight=balanced, penalty=l2, solver=lbfgs;, score=0.515 total time=   0.5s\n",
      "[CV 3/5] END class_weight=balanced, penalty=l2, solver=lbfgs;, score=0.458 total time=   0.5s\n",
      "[CV 5/5] END class_weight=balanced, penalty=l2, solver=lbfgs;, score=0.520 total time=   0.5s\n",
      "[CV 1/5] END class_weight=None, penalty=l1, solver=saga;, score=0.354 total time=   5.2s\n",
      "[CV 1/5] END class_weight=balanced, penalty=l1, solver=saga;, score=0.410 total time=   6.7s\n",
      "[CV 2/5] END class_weight=None, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END class_weight=None, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END class_weight=None, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END class_weight=None, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END class_weight=None, penalty=l2, solver=saga;, score=0.264 total time=   0.7s\n",
      "[CV 4/5] END class_weight=balanced, penalty=l1, solver=saga;, score=0.508 total time=   8.5s\n",
      "[CV 2/5] END class_weight=None, penalty=l2, solver=saga;, score=0.411 total time=   0.8s\n",
      "[CV 3/5] END class_weight=None, penalty=l2, solver=saga;, score=0.441 total time=   0.7s\n",
      "[CV 3/5] END class_weight=balanced, penalty=l1, solver=saga;, score=0.455 total time=   9.7s\n",
      "[CV 4/5] END class_weight=None, penalty=l2, solver=saga;, score=0.390 total time=   0.7s\n",
      "[CV 5/5] END class_weight=balanced, penalty=l1, solver=saga;, score=0.512 total time=   9.1s\n",
      "[CV 5/5] END class_weight=None, penalty=l2, solver=saga;, score=0.344 total time=   0.8s\n",
      "[CV 1/5] END class_weight=None, penalty=l2, solver=lbfgs;, score=0.264 total time=   0.4s\n",
      "[CV 4/5] END class_weight=None, penalty=l2, solver=lbfgs;, score=0.390 total time=   0.5s\n",
      "[CV 5/5] END class_weight=None, penalty=l2, solver=lbfgs;, score=0.344 total time=   0.5s\n",
      "[CV 2/5] END class_weight=balanced, penalty=l1, solver=saga;, score=0.446 total time=  10.6s\n",
      "[CV 2/5] END class_weight=None, penalty=l2, solver=lbfgs;, score=0.411 total time=   1.7s\n",
      "[CV 3/5] END class_weight=None, penalty=l2, solver=lbfgs;, score=0.441 total time=   1.6s\n",
      "[CV 3/5] END class_weight=None, penalty=l1, solver=saga;, score=0.453 total time=   9.4s\n",
      "[CV 5/5] END class_weight=None, penalty=l1, solver=saga;, score=0.388 total time=  10.0s\n",
      "[CV 1/5] END class_weight=None, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END class_weight=None, penalty=l1, solver=saga;, score=0.438 total time=   7.2s\n",
      "[CV 4/5] END class_weight=None, penalty=l1, solver=saga;, score=0.431 total time=   5.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=10000, random_state=43),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', None],\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['saga', 'lbfgs']},\n",
       "             scoring=make_scorer(f1_score, average=None, labels=['Hispanic']),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[344  36   9]\n",
      " [ 23 133  48]\n",
      " [ 24 185 929]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.88      0.88      0.88       389\n",
      "    Hispanic       0.38      0.65      0.48       204\n",
      "       White       0.94      0.82      0.87      1138\n",
      "\n",
      "    accuracy                           0.81      1731\n",
      "   macro avg       0.73      0.78      0.74      1731\n",
      "weighted avg       0.86      0.81      0.83      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 832   50   27]\n",
      " [  38  348   89]\n",
      " [  55  480 2119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.90      0.92      0.91       909\n",
      "    Hispanic       0.40      0.73      0.51       475\n",
      "       White       0.95      0.80      0.87      2654\n",
      "\n",
      "    accuracy                           0.82      4038\n",
      "   macro avg       0.75      0.82      0.76      4038\n",
      "weighted avg       0.87      0.82      0.83      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(log_model_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model_grid.predict(X_test)\n",
    "log_grid_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "log_grid_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curves\n",
    "plot_multiclass_roc(log_model_grid,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    n_classes=3,\n",
    "                    figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[ 281   15   93]\n",
      " [  21   25  158]\n",
      " [  19   33 1086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.88      0.72      0.79       389\n",
      "    Hispanic       0.34      0.12      0.18       204\n",
      "       White       0.81      0.95      0.88      1138\n",
      "\n",
      "    accuracy                           0.80      1731\n",
      "   macro avg       0.68      0.60      0.62      1731\n",
      "weighted avg       0.77      0.80      0.78      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 723   18  168]\n",
      " [  40  133  302]\n",
      " [  31   49 2574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.91      0.80      0.85       909\n",
      "    Hispanic       0.67      0.28      0.39       475\n",
      "       White       0.85      0.97      0.90      2654\n",
      "\n",
      "    accuracy                           0.85      4038\n",
      "   macro avg       0.81      0.68      0.72      4038\n",
      "weighted avg       0.84      0.85      0.83      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rates = []\n",
    "\n",
    "\n",
    "for k in range(1,31):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train,y_train) \n",
    "   \n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    \n",
    "    test_error = 1 - accuracy_score(y_test,y_pred)\n",
    "    test_error_rates.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f9f51f31550>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(range(1,31), test_error_rates, color='blue', linestyle='--', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K_values')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.hlines(y=0.05, xmin = 0, xmax = 30, colors= 'r', linestyles=\"--\")\n",
    "plt.hlines(y=0.06, xmin = 0, xmax = 30, colors= 'r', linestyles=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[ 285   16   88]\n",
      " [  27   45  132]\n",
      " [  31   68 1039]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.83      0.73      0.78       389\n",
      "    Hispanic       0.35      0.22      0.27       204\n",
      "       White       0.83      0.91      0.87      1138\n",
      "\n",
      "    accuracy                           0.79      1731\n",
      "   macro avg       0.67      0.62      0.64      1731\n",
      "weighted avg       0.77      0.79      0.78      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 773   17  119]\n",
      " [  29  229  217]\n",
      " [  50  118 2486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.91      0.85      0.88       909\n",
      "    Hispanic       0.63      0.48      0.55       475\n",
      "       White       0.88      0.94      0.91      2654\n",
      "\n",
      "    accuracy                           0.86      4038\n",
      "   macro avg       0.81      0.76      0.78      4038\n",
      "weighted avg       0.86      0.86      0.86      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train,y_train)\n",
    "eval_metric(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid_Search\n",
    "knn_grid = KNeighborsClassifier()\n",
    "k_values= range(1,31)\n",
    "param_grid = {\"n_neighbors\":k_values, \"p\": [1,2], \n",
    "              \"weights\": ['uniform', \"distance\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_model = GridSearchCV(knn_grid, param_grid, cv=10, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 31), 'p': [1, 2],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[ 279    3  107]\n",
      " [  12   20  172]\n",
      " [  10   12 1116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.93      0.72      0.81       389\n",
      "    Hispanic       0.57      0.10      0.17       204\n",
      "       White       0.80      0.98      0.88      1138\n",
      "\n",
      "    accuracy                           0.82      1731\n",
      "   macro avg       0.77      0.60      0.62      1731\n",
      "weighted avg       0.80      0.82      0.78      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 671   12  226]\n",
      " [  34   92  349]\n",
      " [  20   16 2618]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.93      0.74      0.82       909\n",
      "    Hispanic       0.77      0.19      0.31       475\n",
      "       White       0.82      0.99      0.90      2654\n",
      "\n",
      "    accuracy                           0.84      4038\n",
      "   macro avg       0.84      0.64      0.68      4038\n",
      "weighted avg       0.84      0.84      0.81      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(knn_grid_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best is KNN with k=4, let's keep its scores\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "knn_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "GM0PL5eZ1b7E"
   },
   "source": [
    "## 2. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "P3j_Xk1L1b7E"
   },
   "source": [
    "### Vanilla SVC model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "pro8T6CM19vX"
   },
   "outputs": [],
   "source": [
    "svm = SVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[351  24  14]\n",
      " [ 25 119  60]\n",
      " [ 27 178 933]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.87      0.90      0.89       389\n",
      "    Hispanic       0.37      0.58      0.45       204\n",
      "       White       0.93      0.82      0.87      1138\n",
      "\n",
      "    accuracy                           0.81      1731\n",
      "   macro avg       0.72      0.77      0.74      1731\n",
      "weighted avg       0.85      0.81      0.82      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 865   27   17]\n",
      " [  24  390   61]\n",
      " [  45  387 2222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.93      0.95      0.94       909\n",
      "    Hispanic       0.49      0.82      0.61       475\n",
      "       White       0.97      0.84      0.90      2654\n",
      "\n",
      "    accuracy                           0.86      4038\n",
      "   macro avg       0.79      0.87      0.82      4038\n",
      "weighted avg       0.90      0.86      0.87      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(svm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "svc_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "svc_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "28y9nWxG1b7E"
   },
   "source": [
    "###  SVC Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "4dFocgCo1-0Z"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.linspace(200, 400, 5),\n",
    "    'decision_function_shape': ['ovr', 'ovo'],\n",
    "    'gamma': [\"scale\", \"auto\", 1, 0.1, 0.01],\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight': [\"balanced\", None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(class_weight=\"balanced\")\n",
    "svm_grid = GridSearchCV(model,\n",
    "                              param_grid,\n",
    "                              verbose=3,\n",
    "                              scoring=f1_Hispanic,\n",
    "                              refit=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.413 total time=   2.2s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.463 total time=   2.2s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.458 total time=   2.3s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   2.3s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   2.3s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   2.4s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   2.4s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   2.5s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.528 total time=   1.1s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.504 total time=   1.1s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.404 total time=   1.2s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.6s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.6s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.6s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.6s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.370 total time=   1.1s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.498 total time=   1.3s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.455 total time=   1.2s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.412 total time=   1.0s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.462 total time=   1.0s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.461 total time=   1.0s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.498 total time=   1.1s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.514 total time=   1.3s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.522 total time=   1.1s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.1s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.1s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.1s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.463 total time=   1.0s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.2s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.413 total time=   1.1s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.458 total time=   1.2s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.504 total time=   1.2s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.528 total time=   1.2s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.6s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.7s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.404 total time=   1.3s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.370 total time=   1.2s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.498 total time=   1.3s\n",
      "[CV 1/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.412 total time=   1.0s\n",
      "[CV 2/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.462 total time=   1.1s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.455 total time=   1.2s\n",
      "[CV 3/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.461 total time=   1.0s\n",
      "[CV 4/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.498 total time=   1.0s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.514 total time=   1.3s\n",
      "[CV 5/5] END C=200.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.522 total time=   1.1s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.427 total time=   0.6s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.391 total time=   0.8s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.1s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.437 total time=   0.8s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.2s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.485 total time=   0.8s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.344 total time=   1.2s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.414 total time=   1.1s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.7s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.444 total time=   1.2s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.368 total time=   0.7s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.434 total time=   0.7s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.447 total time=   0.8s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.7s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.485 total time=   0.8s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.503 total time=   1.3s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.459 total time=   1.2s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.1s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.427 total time=   0.7s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.1s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.437 total time=   0.8s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.391 total time=   0.8s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.485 total time=   0.8s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.433 total time=   0.7s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.414 total time=   1.1s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.344 total time=   1.1s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.5s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.6s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.6s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.5s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.444 total time=   1.1s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 1/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.368 total time=   0.7s\n",
      "[CV 2/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.434 total time=   0.7s\n",
      "[CV 3/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.447 total time=   0.8s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.485 total time=   0.8s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.7s\n",
      "[CV 4/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.503 total time=   1.1s\n",
      "[CV 5/5] END C=200.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.459 total time=   1.2s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.1s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.1s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.407 total time=   1.0s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.460 total time=   1.0s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.2s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.466 total time=   1.0s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.515 total time=   1.1s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.525 total time=   1.1s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.5s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.376 total time=   1.3s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.5s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.6s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.6s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.364 total time=   1.3s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.498 total time=   1.3s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.404 total time=   1.0s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.460 total time=   1.0s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.440 total time=   1.4s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.463 total time=   1.1s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.492 total time=   1.4s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.505 total time=   1.1s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.527 total time=   1.1s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.4s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.5s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.407 total time=   1.3s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.460 total time=   1.3s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.5s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.6s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.466 total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.515 total time=   1.4s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.525 total time=   1.5s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   2.3s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   2.4s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   2.4s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   2.3s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   2.3s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.364 total time=   1.8s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.498 total time=   1.9s\n",
      "[CV 2/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.460 total time=   1.4s\n",
      "[CV 1/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.404 total time=   1.4s\n",
      "[CV 3/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.463 total time=   1.4s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.505 total time=   1.5s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.527 total time=   1.5s\n",
      "[CV 4/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.440 total time=   1.9s\n",
      "[CV 5/5] END C=250.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.492 total time=   1.9s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.5s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.424 total time=   0.9s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.397 total time=   0.9s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.447 total time=   0.9s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.3s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.5s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.5s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.522 total time=   0.8s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   2.0s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.9s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.9s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.391 total time=   1.5s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.335 total time=   1.6s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   2.0s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.448 total time=   1.5s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   2.0s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.397 total time=   0.9s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.413 total time=   0.8s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.447 total time=   0.9s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.507 total time=   0.8s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.9s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.497 total time=   1.3s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.453 total time=   1.4s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.397 total time=   0.8s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.1s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.424 total time=   0.7s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.447 total time=   0.8s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.2s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.522 total time=   0.8s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.335 total time=   1.2s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.391 total time=   1.1s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.6s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.6s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.6s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.448 total time=   1.3s\n",
      "[CV 2/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.413 total time=   0.7s\n",
      "[CV 1/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.397 total time=   0.7s\n",
      "[CV 3/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.447 total time=   0.8s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.507 total time=   0.8s\n",
      "[CV 5/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.453 total time=   1.3s\n",
      "[CV 4/5] END C=250.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.497 total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.454 total time=   1.0s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.391 total time=   1.1s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.2s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.474 total time=   1.1s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.525 total time=   1.1s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.522 total time=   1.1s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.6s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.377 total time=   1.4s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.6s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.6s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.365 total time=   1.4s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.481 total time=   1.4s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.399 total time=   1.1s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.460 total time=   1.1s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.471 total time=   1.1s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.521 total time=   1.1s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.428 total time=   1.4s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.482 total time=   1.4s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.522 total time=   1.1s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.391 total time=   1.1s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.454 total time=   1.1s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.474 total time=   1.1s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.525 total time=   1.2s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.522 total time=   1.1s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.6s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.377 total time=   1.4s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.365 total time=   1.4s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.481 total time=   1.5s\n",
      "[CV 2/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.460 total time=   1.1s\n",
      "[CV 1/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.399 total time=   1.1s\n",
      "[CV 3/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.471 total time=   1.1s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.521 total time=   1.2s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.482 total time=   1.5s\n",
      "[CV 4/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.428 total time=   1.5s\n",
      "[CV 5/5] END C=300.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.522 total time=   1.2s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.383 total time=   0.8s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.418 total time=   0.8s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.442 total time=   0.8s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.2s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.500 total time=   0.8s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.327 total time=   1.4s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.6s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.375 total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.7s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.452 total time=   1.3s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.383 total time=   0.8s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.421 total time=   0.8s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.444 total time=   0.8s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.522 total time=   0.8s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.9s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.461 total time=   1.4s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.488 total time=   1.4s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.383 total time=   0.8s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.418 total time=   0.8s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.442 total time=   0.8s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.500 total time=   0.8s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.327 total time=   1.3s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.375 total time=   1.3s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.7s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.7s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.452 total time=   1.4s\n",
      "[CV 1/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.383 total time=   0.8s\n",
      "[CV 2/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.421 total time=   0.8s\n",
      "[CV 3/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.444 total time=   0.8s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.522 total time=   0.8s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 4/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.488 total time=   1.5s\n",
      "[CV 5/5] END C=300.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.461 total time=   1.5s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.391 total time=   1.1s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.444 total time=   1.1s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.473 total time=   1.2s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.527 total time=   1.2s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.528 total time=   1.2s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.8s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.380 total time=   1.5s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.359 total time=   1.5s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.469 total time=   1.5s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.454 total time=   1.1s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.391 total time=   1.2s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.469 total time=   1.2s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.415 total time=   1.5s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.523 total time=   1.2s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.522 total time=   1.2s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.473 total time=   1.6s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.3s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.391 total time=   1.1s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.444 total time=   1.1s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.473 total time=   1.2s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.527 total time=   1.2s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.528 total time=   1.2s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.380 total time=   1.6s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.8s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.359 total time=   1.4s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.469 total time=   1.5s\n",
      "[CV 3/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.469 total time=   1.2s\n",
      "[CV 1/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.391 total time=   1.2s\n",
      "[CV 2/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.454 total time=   1.2s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.523 total time=   1.2s\n",
      "[CV 4/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.415 total time=   1.5s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.473 total time=   1.6s\n",
      "[CV 5/5] END C=350.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.522 total time=   1.2s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.3s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.386 total time=   0.8s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.420 total time=   0.8s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.452 total time=   0.9s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.3s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.489 total time=   0.9s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.433 total time=   0.8s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.331 total time=   1.4s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.7s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.367 total time=   1.4s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.467 total time=   1.5s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.429 total time=   0.8s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.374 total time=   0.9s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.452 total time=   0.8s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.489 total time=   0.9s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.9s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.485 total time=   1.5s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.458 total time=   1.5s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.3s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.386 total time=   0.8s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.420 total time=   0.8s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.4s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.452 total time=   0.8s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.4s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.489 total time=   0.9s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.433 total time=   0.9s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.8s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.331 total time=   1.4s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.7s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.367 total time=   1.4s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.467 total time=   1.5s\n",
      "[CV 2/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.429 total time=   0.8s\n",
      "[CV 1/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.374 total time=   0.9s\n",
      "[CV 3/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.452 total time=   0.9s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.489 total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.433 total time=   0.9s\n",
      "[CV 4/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.485 total time=   1.5s\n",
      "[CV 5/5] END C=350.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.458 total time=   1.5s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.3s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.397 total time=   1.2s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.444 total time=   1.1s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.472 total time=   1.2s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.519 total time=   1.2s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.535 total time=   1.3s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.8s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.376 total time=   1.5s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.363 total time=   1.5s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.464 total time=   1.5s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.393 total time=   1.2s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.438 total time=   1.2s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.473 total time=   1.2s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.419 total time=   1.6s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.521 total time=   1.2s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.454 total time=   1.6s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.533 total time=   1.2s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.2s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.3s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.397 total time=   1.2s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.444 total time=   1.2s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.472 total time=   1.2s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.519 total time=   1.2s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.535 total time=   1.3s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.8s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.376 total time=   1.6s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.363 total time=   1.5s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.464 total time=   1.6s\n",
      "[CV 1/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.393 total time=   1.2s\n",
      "[CV 2/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.438 total time=   1.2s\n",
      "[CV 3/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.473 total time=   1.2s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.521 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.419 total time=   1.7s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.454 total time=   1.7s\n",
      "[CV 5/5] END C=400.0, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.533 total time=   1.2s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.322 total time=   1.3s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.383 total time=   0.9s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.413 total time=   0.9s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.459 total time=   0.9s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=scale, kernel=rbf;, score=0.417 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.477 total time=   0.9s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=auto, kernel=rbf;, score=0.444 total time=   0.9s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.354 total time=   1.7s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.373 total time=   1.8s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.329 total time=   1.5s\n",
      "\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.352 total time=   1.5s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.467 total time=   1.6s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.388 total time=   0.8s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.423 total time=   0.9s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.465 total time=   0.9s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.489 total time=   0.9s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf;, score=0.444 total time=   0.9s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.480 total time=   1.7s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf;, score=0.450 total time=   1.7s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.383 total time=   0.9s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.322 total time=   1.3s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.354 total time=   1.2s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.394 total time=   1.3s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.446 total time=   1.3s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=scale, kernel=rbf;, score=0.417 total time=   1.4s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.413 total time=   0.9s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.459 total time=   0.9s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.444 total time=   0.9s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=auto, kernel=rbf;, score=0.477 total time=   0.9s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.373 total time=   1.7s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.354 total time=   1.8s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.329 total time=   1.5s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.440 total time=   1.8s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.408 total time=   1.8s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf;, score=0.376 total time=   1.8s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.352 total time=   1.5s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.467 total time=   1.5s\n",
      "[CV 2/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.423 total time=   0.8s\n",
      "[CV 1/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.388 total time=   0.8s\n",
      "[CV 3/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.465 total time=   0.8s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.489 total time=   0.8s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf;, score=0.444 total time=   0.8s\n",
      "[CV 4/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.480 total time=   1.4s\n",
      "[CV 5/5] END C=400.0, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf;, score=0.450 total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(class_weight='balanced'), n_jobs=-1,\n",
       "             param_grid={'C': array([200., 250., 300., 350., 400.]),\n",
       "                         'class_weight': ['balanced', None],\n",
       "                         'decision_function_shape': ['ovr', 'ovo'],\n",
       "                         'gamma': ['scale', 'auto', 1, 0.1, 0.01],\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring=make_scorer(f1_score, average=None, labels=['Hispanic']),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 250.0,\n",
       " 'class_weight': 'balanced',\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[340  41   8]\n",
      " [ 28 139  37]\n",
      " [ 26 185 927]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.86      0.87      0.87       389\n",
      "    Hispanic       0.38      0.68      0.49       204\n",
      "       White       0.95      0.81      0.88      1138\n",
      "\n",
      "    accuracy                           0.81      1731\n",
      "   macro avg       0.73      0.79      0.75      1731\n",
      "weighted avg       0.87      0.81      0.83      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 845   42   22]\n",
      " [  24  379   72]\n",
      " [  47  443 2164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.92      0.93      0.93       909\n",
      "    Hispanic       0.44      0.80      0.57       475\n",
      "       White       0.96      0.82      0.88      2654\n",
      "\n",
      "    accuracy                           0.84      4038\n",
      "   macro avg       0.77      0.85      0.79      4038\n",
      "weighted avg       0.89      0.84      0.85      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(svm_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_grid.predict(X_test)\n",
    "svc_grid_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "svc_grid_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_multiclass_roc(svm_grid,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    n_classes=3,\n",
    "                    figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "bDX_iLIls74C"
   },
   "source": [
    "## 3. RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "qaTzrT6P1b7G"
   },
   "source": [
    "### Vanilla RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "gvtqL0Qg2CKf"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[ 297    0   92]\n",
      " [  21   11  172]\n",
      " [  21    2 1115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.88      0.76      0.82       389\n",
      "    Hispanic       0.85      0.05      0.10       204\n",
      "       White       0.81      0.98      0.89      1138\n",
      "\n",
      "    accuracy                           0.82      1731\n",
      "   macro avg       0.84      0.60      0.60      1731\n",
      "weighted avg       0.83      0.82      0.78      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 909    0    0]\n",
      " [   0  475    0]\n",
      " [   0    0 2654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       1.00      1.00      1.00       909\n",
      "    Hispanic       1.00      1.00      1.00       475\n",
      "       White       1.00      1.00      1.00      2654\n",
      "\n",
      "    accuracy                           1.00      4038\n",
      "   macro avg       1.00      1.00      1.00      4038\n",
      "weighted avg       1.00      1.00      1.00      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "rf_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "rf_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MkLAZ_M41b7G"
   },
   "source": [
    "### RF Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "hpmPr3202EbD"
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[400,500],\n",
    "             'criterion': [\"gini\",\"entropy\"],\n",
    "             'max_depth':[10,12,14,16],\n",
    "             'min_samples_split':[18,20,22],\n",
    "             'class_weight': ['balanced',None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(rf_model,\n",
    "                        param_grid,\n",
    "                        verbose=3,\n",
    "                        scoring=f1_Hispanic,\n",
    "                        refit=True,\n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.305 total time=   4.6s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.327 total time=   4.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.335 total time=   4.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.379 total time=   4.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.395 total time=   4.7s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.322 total time=   5.8s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.307 total time=   5.9s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.381 total time=   5.9s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.329 total time=   4.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.374 total time=   4.7s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.320 total time=   4.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.343 total time=   5.8s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.405 total time=   4.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.395 total time=   5.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.307 total time=   4.8s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.320 total time=   6.0s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.343 total time=   4.6s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.400 total time=   4.5s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.389 total time=   5.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.337 total time=   5.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.319 total time=   4.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.438 total time=   5.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.337 total time=   5.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.378 total time=   4.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.345 total time=   4.6s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.320 total time=   5.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.414 total time=   5.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.390 total time=   5.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.313 total time=   5.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.341 total time=   5.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.282 total time=   5.1s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.372 total time=   5.0s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.301 total time=   5.0s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.343 total time=   5.0s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.272 total time=   5.0s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.267 total time=   6.3s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.329 total time=   6.3s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.326 total time=   6.2s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.288 total time=   6.3s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.264 total time=   6.3s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.273 total time=   5.0s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.373 total time=   4.9s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.329 total time=   4.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.270 total time=   5.0s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.389 total time=   5.0s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.329 total time=   6.1s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.340 total time=   6.2s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.297 total time=   6.4s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.319 total time=   5.2s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.417 total time=   6.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.276 total time=   6.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.304 total time=   5.1s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.378 total time=   5.2s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.365 total time=   5.2s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.257 total time=   5.1s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.325 total time=   6.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.381 total time=   6.2s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.321 total time=   6.2s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.267 total time=   5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.438 total time=   6.2s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.299 total time=   6.3s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.351 total time=   5.2s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.304 total time=   5.3s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.312 total time=   5.5s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.198 total time=   5.5s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.263 total time=   6.8s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.284 total time=   5.5s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.354 total time=   6.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.254 total time=   6.8s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.286 total time=   6.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.124 total time=   6.9s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.313 total time=   5.5s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.306 total time=   5.4s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.353 total time=   5.5s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.212 total time=   5.5s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.276 total time=   7.0s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.333 total time=   6.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.290 total time=   6.8s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.333 total time=   6.8s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.312 total time=   5.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.248 total time=   6.9s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.321 total time=   5.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.278 total time=   5.6s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.348 total time=   5.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.230 total time=   5.5s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.282 total time=   6.8s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.312 total time=   6.9s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.291 total time=   6.8s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.346 total time=   7.0s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.250 total time=   5.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.241 total time=   6.9s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.306 total time=   5.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.244 total time=   5.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.317 total time=   5.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.175 total time=   5.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.239 total time=   7.2s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.308 total time=   7.3s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.229 total time=   7.3s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.246 total time=   5.6s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.288 total time=   7.1s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.189 total time=   7.3s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.316 total time=   5.7s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.271 total time=   5.6s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.310 total time=   5.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.207 total time=   5.9s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.307 total time=   7.1s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.271 total time=   7.2s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.271 total time=   7.1s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.280 total time=   5.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.328 total time=   7.3s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.183 total time=   7.2s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.291 total time=   5.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.317 total time=   5.8s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.338 total time=   5.7s\n",
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.229 total time=   5.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.292 total time=   7.1s\n",
      "[CV 2/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.327 total time=   7.1s\n",
      "[CV 3/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.313 total time=   7.2s\n",
      "[CV 4/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.321 total time=   7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END class_weight=balanced, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.229 total time=   7.1s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.354 total time=   6.9s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.366 total time=   7.1s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.298 total time=   7.1s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.416 total time=   7.1s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.329 total time=   7.0s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.309 total time=   8.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.395 total time=   8.7s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.315 total time=   8.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.382 total time=   8.8s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.346 total time=   7.1s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.386 total time=   6.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.327 total time=   8.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.318 total time=   6.9s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.405 total time=   6.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.279 total time=   6.9s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.333 total time=   8.6s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.398 total time=   8.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.324 total time=   6.9s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.335 total time=   8.9s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.420 total time=   8.5s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.329 total time=   8.8s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.402 total time=   6.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.317 total time=   6.9s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.425 total time=   6.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.305 total time=   6.9s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.299 total time=   8.6s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.386 total time=   8.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.317 total time=   8.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.405 total time=   8.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.288 total time=   7.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.347 total time=   8.6s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.327 total time=   7.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.318 total time=   7.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.326 total time=   7.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.227 total time=   7.6s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.301 total time=   9.3s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.291 total time=   9.3s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.359 total time=   9.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.348 total time=   9.4s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.280 total time=   7.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.222 total time=   9.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.346 total time=   7.3s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.289 total time=   7.6s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.350 total time=   7.3s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.247 total time=   7.3s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.310 total time=   9.5s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.346 total time=   9.3s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.289 total time=   9.4s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.336 total time=   9.2s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.310 total time=   7.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.238 total time=   9.2s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.362 total time=   7.3s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.268 total time=   7.3s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.395 total time=   7.5s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.260 total time=   7.3s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.289 total time=   9.2s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.395 total time=   9.0s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.293 total time=   9.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.386 total time=   9.1s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.275 total time=   7.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.263 total time=   9.1s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.278 total time=   7.9s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.290 total time=   7.9s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.310 total time=   7.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.183 total time=   7.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.297 total time=   9.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.275 total time=  10.0s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.245 total time=   9.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.306 total time=   9.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.280 total time=   7.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.167 total time=   9.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.324 total time=   7.6s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.257 total time=   7.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.331 total time=   7.7s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.206 total time=   7.9s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.309 total time=   9.5s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.351 total time=   9.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.286 total time=   9.6s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.307 total time=   7.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.366 total time=   9.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.232 total time=   9.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.346 total time=   7.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.271 total time=   7.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.356 total time=   7.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.205 total time=   7.4s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.291 total time=   9.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.318 total time=   9.2s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.284 total time=   9.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.348 total time=   9.5s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.256 total time=   8.1s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.210 total time=   9.4s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.290 total time=   7.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.254 total time=   7.9s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.276 total time=   7.9s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.188 total time=   7.8s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.294 total time=   9.7s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.246 total time=   9.9s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.313 total time=   7.8s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.239 total time=  10.1s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.302 total time=   9.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.144 total time=   9.7s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.324 total time=   7.6s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.284 total time=   7.6s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.308 total time=   7.8s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.182 total time=   7.8s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.284 total time=   9.5s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.338 total time=  10.0s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.266 total time=   9.6s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.312 total time=   7.6s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.312 total time=   9.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.179 total time=   9.6s\n",
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.338 total time=   7.6s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.282 total time=   7.7s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.331 total time=   7.6s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.210 total time=   7.8s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.078 total time=   5.4s\n",
      "[CV 1/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.267 total time=   9.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.361 total time=   9.4s\n",
      "[CV 3/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.262 total time=   9.5s\n",
      "[CV 4/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.346 total time=   9.6s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.038 total time=   5.4s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.061 total time=   5.4s\n",
      "[CV 5/5] END class_weight=balanced, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.211 total time=   9.5s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.021 total time=   5.3s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.000 total time=   5.4s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.060 total time=   6.7s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.038 total time=   6.7s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.021 total time=   6.8s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.041 total time=   6.7s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.097 total time=   5.4s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.041 total time=   6.7s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.037 total time=   5.3s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.021 total time=   5.3s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.000 total time=   5.3s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.041 total time=   5.3s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.040 total time=   6.7s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.037 total time=   6.6s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.099 total time=   5.3s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.041 total time=   6.7s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.021 total time=   6.7s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.021 total time=   6.6s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.038 total time=   5.3s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.021 total time=   5.3s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.000 total time=   5.3s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.040 total time=   5.2s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.059 total time=   6.5s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.038 total time=   6.8s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.021 total time=   6.6s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.097 total time=   5.9s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.021 total time=   6.6s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.041 total time=   6.6s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.037 total time=   6.0s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.040 total time=   6.0s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.021 total time=   6.1s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.040 total time=   6.1s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.115 total time=   7.5s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.037 total time=   7.5s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.061 total time=   7.3s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.021 total time=   7.4s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.060 total time=   5.8s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.041 total time=   7.5s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.037 total time=   5.9s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.040 total time=   6.0s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.041 total time=   5.9s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.061 total time=   5.9s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.078 total time=   7.3s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.038 total time=   7.4s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.041 total time=   7.4s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.059 total time=   5.9s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.021 total time=   7.5s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.040 total time=   7.4s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.037 total time=   5.9s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.020 total time=   5.9s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.000 total time=   5.9s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.059 total time=   5.9s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.096 total time=   7.3s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.037 total time=   7.5s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.021 total time=   7.4s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.041 total time=   7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.078 total time=   6.4s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.060 total time=   7.4s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.037 total time=   6.3s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.079 total time=   6.4s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.021 total time=   6.3s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.059 total time=   6.5s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.019 total time=   7.9s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.132 total time=   8.0s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.040 total time=   8.0s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.115 total time=   6.3s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.021 total time=   8.0s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.041 total time=   7.9s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.055 total time=   6.3s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.021 total time=   6.4s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.000 total time=   6.3s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.040 total time=   6.4s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.078 total time=   8.0s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.057 total time=   7.9s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.040 total time=   8.0s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.021 total time=   7.9s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.117 total time=   6.3s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.060 total time=   7.9s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.037 total time=   6.2s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.061 total time=   6.4s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.021 total time=   6.2s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.061 total time=   6.3s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.060 total time=   7.9s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.037 total time=   7.8s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.060 total time=   8.0s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.021 total time=   7.9s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.115 total time=   6.7s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.041 total time=   7.8s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.055 total time=   6.8s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.059 total time=   6.7s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.041 total time=   6.7s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.040 total time=   6.7s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.114 total time=   8.5s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.056 total time=   8.3s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.115 total time=   6.6s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.041 total time=   8.3s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.041 total time=   8.3s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.061 total time=   8.4s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.056 total time=   6.7s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.059 total time=   6.6s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.000 total time=   6.7s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.061 total time=   6.7s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.097 total time=   8.3s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.037 total time=   8.4s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.041 total time=   8.2s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.040 total time=   6.6s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.021 total time=   8.4s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.041 total time=   8.4s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.038 total time=   6.8s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.060 total time=   6.7s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.041 total time=   6.7s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.040 total time=   6.7s\n",
      "[CV 1/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.078 total time=   8.4s\n",
      "[CV 2/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.038 total time=   8.3s\n",
      "[CV 3/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.020 total time=   8.4s\n",
      "[CV 4/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.061 total time=   8.5s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.040 total time=   7.4s\n",
      "[CV 5/5] END class_weight=None, criterion=gini, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.060 total time=   8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.019 total time=   7.3s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.000 total time=   7.5s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.021 total time=   7.6s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=400;, score=0.041 total time=   7.5s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.041 total time=   9.5s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.039 total time=   9.6s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.061 total time=   9.4s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.000 total time=   7.4s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.000 total time=   9.7s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=18, n_estimators=500;, score=0.041 total time=   9.3s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.021 total time=   7.4s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.020 total time=   7.5s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.041 total time=   7.3s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=400;, score=0.061 total time=   7.7s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.021 total time=   9.2s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.020 total time=   9.1s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.041 total time=   7.4s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.000 total time=   9.3s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.000 total time=   9.1s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=20, n_estimators=500;, score=0.041 total time=   9.1s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.039 total time=   7.2s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.021 total time=   7.5s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.000 total time=   7.2s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=400;, score=0.021 total time=   7.3s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.041 total time=   9.2s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.038 total time=   9.1s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.021 total time=   9.0s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.000 total time=   9.1s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=10, min_samples_split=22, n_estimators=500;, score=0.041 total time=   9.1s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.060 total time=   8.2s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.038 total time=   7.8s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.041 total time=   7.9s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.021 total time=   8.0s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=400;, score=0.061 total time=   7.9s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.041 total time=   9.6s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.038 total time=   9.7s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.000 total time=   9.7s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.099 total time=   7.7s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.000 total time=  10.0s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=18, n_estimators=500;, score=0.061 total time=   9.7s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.039 total time=   7.6s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.061 total time=   7.8s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.000 total time=   7.6s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=400;, score=0.041 total time=   7.8s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.021 total time=   9.6s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.020 total time=   9.6s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.041 total time=  10.1s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.041 total time=   7.8s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.021 total time=   9.6s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.038 total time=   7.5s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=20, n_estimators=500;, score=0.041 total time=   9.7s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.041 total time=   7.6s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.021 total time=   7.6s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=400;, score=0.061 total time=   7.6s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.060 total time=   9.9s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.039 total time=   9.6s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.000 total time=   9.5s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.098 total time=   8.0s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.021 total time=   9.5s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=12, min_samples_split=22, n_estimators=500;, score=0.041 total time=   9.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.039 total time=   7.9s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.081 total time=   8.1s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.041 total time=   8.1s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=400;, score=0.021 total time=   8.2s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.041 total time=   9.8s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.038 total time=  10.0s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.041 total time=   9.9s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.021 total time=  10.0s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.060 total time=   7.9s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=18, n_estimators=500;, score=0.041 total time=   9.8s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.057 total time=   8.0s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.061 total time=   8.3s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.021 total time=   7.9s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=400;, score=0.061 total time=   8.0s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.061 total time=   9.9s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.039 total time=  10.0s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.021 total time=  10.0s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.000 total time=   9.8s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.041 total time=   8.1s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.019 total time=   7.7s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=20, n_estimators=500;, score=0.061 total time=  10.0s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.041 total time=   7.7s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.021 total time=   7.8s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=400;, score=0.041 total time=   7.9s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.041 total time=  10.1s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.019 total time=  10.0s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.021 total time=  10.3s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.078 total time=   8.4s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.000 total time=  10.0s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=14, min_samples_split=22, n_estimators=500;, score=0.061 total time=  10.3s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.039 total time=   8.2s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.041 total time=   8.4s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.021 total time=   8.2s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=400;, score=0.041 total time=   8.1s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.061 total time=  10.4s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.081 total time=  10.0s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.038 total time=  10.1s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.060 total time=   8.0s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.021 total time=  10.3s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=18, n_estimators=500;, score=0.061 total time=  10.0s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.038 total time=   8.1s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.021 total time=   8.0s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.041 total time=   8.0s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=400;, score=0.000 total time=   8.4s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.061 total time=  10.1s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.019 total time=  10.2s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.061 total time=  10.2s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.000 total time=  10.0s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.061 total time=   7.9s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=20, n_estimators=500;, score=0.061 total time=  10.1s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.019 total time=   7.8s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.000 total time=   8.2s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.021 total time=   7.7s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=400;, score=0.041 total time=   7.7s\n",
      "[CV 1/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.060 total time=   9.3s\n",
      "[CV 2/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.038 total time=   9.0s\n",
      "[CV 3/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.021 total time=   8.9s\n",
      "[CV 4/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.000 total time=   8.3s\n",
      "[CV 5/5] END class_weight=None, criterion=entropy, max_depth=16, min_samples_split=22, n_estimators=500;, score=0.041 total time=   7.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', None],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 12, 14, 16],\n",
       "                         'min_samples_split': [18, 20, 22],\n",
       "                         'n_estimators': [400, 500]},\n",
       "             scoring=make_scorer(f1_score, average=None, labels=['Hispanic']),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_split': 20,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[ 319   12   58]\n",
      " [  25   68  111]\n",
      " [  44   77 1017]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.82      0.82      0.82       389\n",
      "    Hispanic       0.43      0.33      0.38       204\n",
      "       White       0.86      0.89      0.88      1138\n",
      "\n",
      "    accuracy                           0.81      1731\n",
      "   macro avg       0.70      0.68      0.69      1731\n",
      "weighted avg       0.80      0.81      0.80      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 875    4   30]\n",
      " [   5  446   24]\n",
      " [  43   98 2513]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.95      0.96      0.96       909\n",
      "    Hispanic       0.81      0.94      0.87       475\n",
      "       White       0.98      0.95      0.96      2654\n",
      "\n",
      "    accuracy                           0.95      4038\n",
      "   macro avg       0.91      0.95      0.93      4038\n",
      "weighted avg       0.95      0.95      0.95      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(rf_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_grid.predict(X_test)\n",
    "rf_grid_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "rf_grid_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_multiclass_roc(svm_grid,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    n_classes=3,\n",
    "                    figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sittingheight</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyeheightsitting</th>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interpupillarybreadth</th>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heelbreadth</th>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elbowrestheight</th>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poplitealheight</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shoulderlength</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bimalleolarbreadth</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earbreadth</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature Importance\n",
       "sittingheight                       0.045\n",
       "eyeheightsitting                    0.041\n",
       "interpupillarybreadth               0.039\n",
       "heelbreadth                         0.037\n",
       "elbowrestheight                     0.033\n",
       "...                                   ...\n",
       "poplitealheight                     0.006\n",
       "shoulderlength                      0.006\n",
       "bimalleolarbreadth                  0.006\n",
       "earbreadth                          0.005\n",
       "Gender                              0.005\n",
       "\n",
       "[94 rows x 1 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feature_imp = pd.DataFrame(index = X.columns, data = rf.feature_importances_,\n",
    "                              columns = [\"Feature Importance\"]).sort_values(\"Feature Importance\", ascending = False)\n",
    "rf_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20 Most important features\n",
    "sns.barplot(x=rf_feature_imp[\"Feature Importance\"].head(20), y=rf_feature_imp.index[:20])\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "PvcPc4V81b7H"
   },
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "MuxxUFoW1b7H"
   },
   "source": [
    "### Vanilla XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50715901, 2.83368421, 1.48074807, ..., 0.50715901, 0.50715901,\n",
       "       1.48074807])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "classes_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:42:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train,y_train,sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[ 340    8   41]\n",
      " [  19   59  126]\n",
      " [  25   33 1080]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.89      0.87      0.88       389\n",
      "    Hispanic       0.59      0.29      0.39       204\n",
      "       White       0.87      0.95      0.91      1138\n",
      "\n",
      "    accuracy                           0.85      1731\n",
      "   macro avg       0.78      0.70      0.72      1731\n",
      "weighted avg       0.84      0.85      0.84      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 909    0    0]\n",
      " [   0  475    0]\n",
      " [   0    0 2654]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       1.00      1.00      1.00       909\n",
      "    Hispanic       1.00      1.00      1.00       475\n",
      "       White       1.00      1.00      1.00      2654\n",
      "\n",
      "    accuracy                           1.00      4038\n",
      "   macro avg       1.00      1.00      1.00      4038\n",
      "weighted avg       1.00      1.00      1.00      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "xgb_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "xgb_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "p3gH5QvE1b7I"
   },
   "source": [
    "### XGBoost Model GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "72E3Cmnm2KOE"
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\":[100, 300],\n",
    "              'max_depth':[3,5,6],\n",
    "              \"learning_rate\": [0.1, 0.3],\n",
    "              \"subsample\":[0.5, 1],\n",
    "              \"colsample_bytree\":[0.5, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.5s\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:47:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=   8.1s\n",
      "[23:48:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  24.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  24.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  24.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  24.4s\n",
      "[23:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  24.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  24.5s\n",
      "[23:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  23.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  23.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[23:48:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  22.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:48:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=  42.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=  42.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=  43.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=  42.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time=  42.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time=  44.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time=  44.5s\n",
      "[23:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time=  44.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  19.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  19.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:49:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time=  42.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  21.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time=  42.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  21.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  21.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time=  50.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time=  50.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time=  51.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time=  51.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time=  51.3s\n",
      "[23:50:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:50:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time=  54.7s\n",
      "[23:51:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=   7.6s\n",
      "[23:51:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=   7.7s\n",
      "[23:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time=  55.4s\n",
      "[23:51:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time=  56.7s\n",
      "[23:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=   7.9s\n",
      "[23:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=   7.9s\n",
      "[23:51:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=   7.9s\n",
      "[23:51:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  23.2s\n",
      "[23:51:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  23.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:51:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  23.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  23.5s\n",
      "[23:51:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  23.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  23.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  23.3s\n",
      "[23:52:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[23:52:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  22.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  15.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  15.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  15.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  36.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  36.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  37.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  37.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  37.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  38.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  38.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:53:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:53:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  37.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  37.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  19.2s\n",
      "[23:53:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  18.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  39.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  40.1s\n",
      "[23:53:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  39.9s\n",
      "[23:53:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[23:54:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   8.8s\n",
      "[23:54:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  41.8s\n",
      "[23:54:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  44.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  45.0s\n",
      "[23:54:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:54:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  45.8s\n",
      "[23:54:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=  10.1s\n",
      "[23:54:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=  11.1s\n",
      "[23:54:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=  11.2s\n",
      "[23:54:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1; total time=  11.2s\n",
      "[23:54:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  55.7s\n",
      "[23:54:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  33.6s\n",
      "[23:54:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  57.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  34.0s\n",
      "[23:55:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  34.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  33.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.5; total time=  34.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  34.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:55:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  33.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  33.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  33.6s\n",
      "[23:55:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:55:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.6s\n",
      "[23:55:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:55:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1; total time=  32.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  23.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  23.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  23.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:55:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  23.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1; total time=  23.8s\n",
      "[23:55:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:55:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.5; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time= 1.1min\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:56:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.5; total time=  28.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  31.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  30.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=1; total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time= 1.2min\n",
      "[23:58:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time= 1.2min\n",
      "[23:58:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.0s\n",
      "[23:58:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=0.5; total time= 1.3min\n",
      "[23:59:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.2s\n",
      "[23:59:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[23:59:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.4min\n",
      "[23:59:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[23:59:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.4min\n",
      "[23:59:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.5s\n",
      "[23:59:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.4min\n",
      "[23:59:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=  11.7s\n",
      "[23:59:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=  11.8s\n",
      "[23:59:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=  11.8s\n",
      "[23:59:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=  11.9s\n",
      "[23:59:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=100, subsample=1; total time=  11.8s\n",
      "[23:59:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  35.2s\n",
      "[23:59:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  35.1s\n",
      "[23:59:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  35.2s\n",
      "[23:59:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  35.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=0.5; total time=  35.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=6, n_estimators=300, subsample=1; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  24.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  36.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  23.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  36.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, n_estimators=300, subsample=1; total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  22.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  22.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=1; total time=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  52.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  52.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  54.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  54.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=0.5; total time=  55.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  57.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  57.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  57.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.5; total time=  26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  56.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, n_estimators=300, subsample=1; total time=  56.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:02:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  28.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=1; total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  57.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  58.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakantekin/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  58.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  58.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=0.5; total time=  56.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  57.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  57.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  54.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  31.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=6, n_estimators=300, subsample=1; total time=  26.5s\n",
      "[00:03:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_grid_model = GridSearchCV(xgb_model, \n",
    "                              param_grid, \n",
    "                              scoring=f1_Hispanic, \n",
    "                              n_jobs = -1,refit=True, \n",
    "                              verbose = 2).fit(X_train, y_train,sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 300,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set_Scores \n",
      "----------------\n",
      "[[344  17  28]\n",
      " [ 21  97  86]\n",
      " [ 31 113 994]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.87      0.88      0.88       389\n",
      "    Hispanic       0.43      0.48      0.45       204\n",
      "       White       0.90      0.87      0.89      1138\n",
      "\n",
      "    accuracy                           0.83      1731\n",
      "   macro avg       0.73      0.74      0.74      1731\n",
      "weighted avg       0.84      0.83      0.83      1731\n",
      "\n",
      "\n",
      "Train_Set_Scores \n",
      "----------------\n",
      "[[ 898    3    8]\n",
      " [   0  468    7]\n",
      " [  27  107 2520]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.97      0.99      0.98       909\n",
      "    Hispanic       0.81      0.99      0.89       475\n",
      "       White       0.99      0.95      0.97      2654\n",
      "\n",
      "    accuracy                           0.96      4038\n",
      "   macro avg       0.92      0.97      0.95      4038\n",
      "weighted avg       0.97      0.96      0.96      4038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(xgb_grid_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_grid_model.predict(X_test)\n",
    "xgb_grid_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "xgb_grid_recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_multiclass_roc_for_tree(xgb_grid_model, \n",
    "                             X_test, \n",
    "                             y_test, \n",
    "                             n_classes=3, \n",
    "                             figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elbowrestheight</th>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buttockpopliteallength</th>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sittingheight</th>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buttockkneelength</th>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functionalleglength</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shouldercircumference</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bideltoidbreadth</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowerthighcircumference</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buttockcircumference</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature Importance\n",
       "Gender                                0.060\n",
       "elbowrestheight                       0.048\n",
       "buttockpopliteallength                0.041\n",
       "sittingheight                         0.032\n",
       "buttockkneelength                     0.030\n",
       "...                                     ...\n",
       "functionalleglength                   0.005\n",
       "shouldercircumference                 0.005\n",
       "bideltoidbreadth                      0.004\n",
       "lowerthighcircumference               0.004\n",
       "buttockcircumference                  0.003\n",
       "\n",
       "[94 rows x 1 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_feature_imp = pd.DataFrame(index = X.columns, data = xgb.feature_importances_,\n",
    "                              columns = [\"Feature Importance\"]).sort_values(\"Feature Importance\", ascending = False)\n",
    "xgb_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20 Most important features\n",
    "sns.barplot(x=xgb_feature_imp[\"Feature Importance\"].head(20), y=xgb_feature_imp.index[:20])\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({\"Model\": [\"Logistic\", \"Log_Grid\", \"KNN\", \"SVC\", \"SVC_Grid\",\n",
    "                                  \"RF\", \"RF_Grid\", \"XGB\", \"XGB_Grid\"],\n",
    "                        \"F1\": [log_f1, log_grid_f1, knn_f1 , svc_f1, svc_grid_f1,\n",
    "                               rf_f1, rf_grid_f1, xgb_f1, xgb_grid_f1],\n",
    "                        \"Recall\": [log_recall, log_grid_recall, knn_recall,\n",
    "                                   svc_recall, svc_grid_recall,rf_recall,\n",
    "                                   rf_grid_recall, xgb_recall, xgb_grid_recall]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def labels(ax):\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()                        # get bar length\n",
    "        ax.text(width,                               # set the text at 1 unit right of the bar\n",
    "                p.get_y() + p.get_height() / 2,      # get Y coordinate + X coordinate / 2\n",
    "                '{:1.3f}'.format(width),             # set variable to display, 2 decimals\n",
    "                ha = 'left',                         # horizontal alignment\n",
    "                va = 'center')                       # vertical alignment\n",
    "    \n",
    "plt.figure(figsize=(14,10))\n",
    "plt.subplot(311)\n",
    "compare = compare.sort_values(by=\"F1\", ascending=False)\n",
    "ax=sns.barplot(x=\"F1\", y=\"Model\", data=compare, palette=\"crest\")\n",
    "labels(ax)\n",
    "\n",
    "plt.subplot(312)\n",
    "compare = compare.sort_values(by=\"Recall\", ascending=False)\n",
    "ax=sns.barplot(x=\"Recall\", y=\"Model\", data=compare, palette=\"crest\")\n",
    "labels(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "WvWpInu21b7L"
   },
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K7UZHtvu1b62",
    "C5lJeTBu1b65",
    "TMjCTEG51b67",
    "CS5-GZy0sl4s",
    "zfi_NOw0s2fM",
    "p3gH5QvE1b7I",
    "9hxUcvZG1b7J",
    "9Rqk02x61b7L",
    "aoKU_HZR1b7M",
    "1hBIqmFL1b7O",
    "AVnS0UKO1b7P"
   ],
   "name": "soldier_race_project_students.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "interpreter": {
   "hash": "e4e90950cb561445fc7289d5187c528b28750a487d008a70b474c773afaf79b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python397jvsc74a57bd0550e15ae2ac2d52031531f851d8135c5a0bd4587619443209f91706b788d6dfa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 527,
   "position": {
    "height": "40px",
    "left": "1034px",
    "right": "20px",
    "top": "185px",
    "width": "661px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
